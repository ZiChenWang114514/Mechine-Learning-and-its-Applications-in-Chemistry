{"cells":[{"cell_type":"markdown","id":"__bohr_old_version_cellId_0__","metadata":{},"source":["# 快速开始 PyTorch｜使用 Python 建立深度学习模型"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_1__","metadata":{},"source":["<a href=\"https://bohrium.dp.tech/notebook/b014bcccd07c488b9349cda979504fd7\" target=\"_blank\"><img src=\"https://cdn.dp.tech/bohrium/web/static/images/open-in-bohrium.svg\" alt=\"Open In Bohrium\"/></a>"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_2__","metadata":{},"source":["<div style=\"color:black; background-color:#FFF3E9; border: 1px solid #FFE0C3; border-radius: 10px; margin-bottom:1rem\">\n","    <p style=\"margin:1rem; padding-left: 1rem; line-height: 2.5;\">\n","        ©️ <b><i>Copyright 2023 @ Authors</i></b><br/>\n","        <i>作者：<a href=\"mailto:hh@shao.ac.cn\"><b>阙浩辉 📨 </b></a></i><br/>\n","        <i>日期：2023-05-09</i><br/>\n","        <i>共享协议：</a>本作品采用<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。</i>\n","    </p>\n","</div>"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_3__","metadata":{},"source":["🎯 <b style='color:purple'>本教程旨在<u>快速掌握</u>使用 PyTorch 建立深度学习模型的范式周期。</b>\n","\n","* 一键运行，你可以快速在实践中检验你的想法。\n","\n","* 丰富完善的注释，对于入门者友好。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_4__","metadata":{},"source":["**在 [Bohrium Notebook](https://bohrium-doc.dp.tech/docs/userguide/Notebook) 界面，你可以点击界面上方蓝色按钮 `开始连接`，选择 `bohrium-notebook` 镜像及任何一款节点配置，稍等片刻即可运行。**\n","\n","<div style=\"width:auto; height:2px; background:linear-gradient(244deg,rgba(0,0,0,0) 0%,rgba(0,0,0,0.5) 50%,rgba(0,0,0,1) 100%)\"></div>"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_5__","metadata":{},"source":["## 目标\n","\n","> **掌握使用 PyTorch 建立深度学习模型的范式周期，并跟随完整案例学习如何应用于预测任务。**\n","\n","在学习本教程后，你将能够：\n","\n","- 初识 PyTorch，安装 PyTorch 并验证其运行。\n","- 通过五个步骤了解建立、拟合和验证 PyTorch 模型的范式周期。\n","- 掌握如何为回归、分类预测任务建立 PyTorch 深度学习模型。\n","\n","**阅读该教程【最多】约需 60 分钟，让我们开始吧！**"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_6__","metadata":{},"source":["## 目录\n","\n","* [背景](#background)\n","* [实践](#practice)\n","  * [1 认识 PyTorch](#whatispytorch)\n","    * [1.1 Torch 与 PyTorch](#1-1)\n","    * [1.2 安装 PyTorch](#1-2)\n","    * [1.3 验证安装并查看 PyTorch 版本](#1-3)\n","  * [2 PyTorch 深度学习模型的建立范式](#pytorchdeeplearningmodellife-cycle)\n","    * [2.1 准备数据](#2-1)\n","    * [2.2 定义模型](#2-2)\n","    * [2.3 训练模型](#2-3)\n","    * [2.4 评估模型](#2-4)\n","    * [2.5 做出预测](#2-5)\n","  * [3 为预测任务建立 PyTorch 深度学习模型](#developpytorchdeeplearningmodels)\n","    * [3.1 建立二分类任务的多层感知机模型](#3-1)\n","    * [3.2 建立多分类任务的多层感知机模型](#3-2)\n","    * [3.3 建立回归任务的多层感知机模型](#3-3)\n","    * [3.4 建立图像分类的卷积神经网络模型](#3-4)\n","* [总结](#summary)\n","* [进一步阅读](#furtherreading)\n","* [参考](#references)\n","\n","![Photo by Dimitry B., some rights reserved.](https://machinelearningmastery.com/wp-content/uploads/2020/03/PyTorch-Tutorial-How-to-Develop-Deep-Learning-Models.jpg)"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_7__","metadata":{},"source":["## 背景 <a id ='background'></a>\n","\n","**你不需要理解所有的事（至少目前是）。** 你的目标是从头到尾完成本教程并获得结果。你不需要在第一次尝试时就了解所有内容。边学习边写下你的问题。使用丰富的 API 文档来了解你正在使用的所有功能。\n","\n","**你不需要精通数学原理。** 数学是描述算法如何工作的基本方式，特别是线性代数、概率和微积分的工具。这些并不是你可以用来了解算法如何工作的唯一工具。你还可以通过使用代码并探索具有不同输入和输出的算法行为来增进了解。了解数学不会告诉你选择哪种算法或如何最好地配置它。你只能通过精心控制的实验来发现这一点。\n","\n","**你不需要知道算法是如何工作的。** 了解限制以及如何配置深度学习算法非常重要。但是学习算法可以稍后进行。你需要在很长一段时间内慢慢建立这种算法知识。今天，首先要熟悉这个平台。\n","\n","**你不需要精通 Python。** 如果你不熟悉 Python 语言，不要担心，Python 的语法是直观的。就像其他语言一样，你只需要专注于函数调用（例如 function（））和赋值（例如 a = “b”）（这已包括了大部分使用场景）。只需开始，稍后再深入了解详细信息。\n","\n","**你不需要成为深度学习专家。** 你可以稍后了解各种算法的优点和局限性，并且你可以阅读大量教程来复习深度学习项目的步骤。\n","\n","**你需要提前了解以下基础知识：**\n","* Python 基础，例如 *class* 和 *function* 的知识。如果你不了解，推荐阅读：\n","    - [Python 函数式编程](https://www.liaoxuefeng.com/wiki/1016959663602400/1017328525009056)\n","    - [Python 类和实例](https://www.liaoxuefeng.com/wiki/1016959663602400/1017496031185408)\n","* 深度学习的基本概念，例如关于什么是特征和标签、训练集和测试集，什么是神经网络。如果你不了解，推荐阅读：\n","    - [训练集、验证集和测试集](https://zhuanlan.zhihu.com/p/48976706)\n","    - [神经网络](https://zh.wikipedia.org/wiki/人工神经网络)"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_8__","metadata":{},"source":["## 实践 <a id='practice'></a>"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_9__","metadata":{},"source":["### 1 认识 PyTorch <a id='whatispytorch'></a>\n","\n","在这一部分，你会了解什么是 PyTorch，在 Bohrium 中使用 PyTorch，验证并查看版本。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_10__","metadata":{},"source":["#### 1.1 什么是 PyTorch [1] <a id='1-1'></a>\n","\n","[PyTorch](https://github.com/pytorch/pytorch) 是由 Facebook 开发和维护的用于深度学习的开源 Python 库。 \n","\n","该项目于 2016 年启动，并迅速成为开发人员和研究人员中流行的框架。 \n","\n","[Torch](https://github.com/torch/torch7) (*Torch7*) 是一个用 C 编写的用于深度学习的开源项目，通常通过 Lua 接口使用。它是 PyTorch 的前身项目，不再积极开发。 PyTorch 在名称中包含 *“Torch”* 以感谢先前的 torch 库，使用 *\"Py\"* 作为前缀以表明聚焦于 Python。 \n","\n","PyTorch API 简单灵活，使其成为学术界和研究人员开发新的深度学习模型和应用程序的最爱之一。同时，广泛的应用衍生了许多针对特定应用（例如文本、计算机视觉和音频数据）的扩展，并且可作为预训练模型直接使用。因此，它可能是学术界使用最多的库。 \n","\n","与 [Keras](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/) 等更简单的界面相比，PyTorch 的灵活性是以易用性为代价的，尤其是对于初学者而言。选择 PyTorch 而不是 Keras 的意味着放弃了一些易用性、需要面对更陡峭的学习曲线、以及使用更多的代码以获得更大的灵活性，也许还有一个更有活力的学术社区。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_11__","metadata":{},"source":["#### 1.2 安装 Pytorch <a id='1-2'></a>\n","\n","本教程是一个 [Bohrium](https://www.dp.tech/product/bohrium) Notebook。**Python 程序可直接在浏览器中运行，Bohrium 已安装 PyTorch**。这是学习和使用 PyTorch 的好方法。\n","\n","要按照本教程进行操作，请点击本页顶部的按钮，在 Bohrium Notebook 中运行本笔记本。 \n","\n","1. 你可以点击界面上方蓝色按钮 `开始连接`，选择 `bohrium-notebook` 镜像及任何一款计算机型，稍等片刻即可运行。\n","\n","2. 若要运行笔记本中的所有代码，请点击左上角“ **运行全部单元格** ”。若要一次运行一个代码单元，请选择需要运行的单元格，然后点击左上角 **“运行选中的单元格”** 图标。\n","\n","如果你的 Bohrium 镜像尚未安装 PyTorch， 也可快速通过 pip 安装 torch:"]},{"cell_type":"code","execution_count":46,"id":"__bohr_old_version_cellId_12__","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n","Requirement already satisfied: torch in c:\\users\\11234\\anaconda3\\envs\\myenv\\lib\\site-packages (1.13.1+cu117)\n","Requirement already satisfied: typing-extensions in c:\\users\\11234\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (4.7.1)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: There was an error checking the latest version of pip.\n"]}],"source":["! pip install torch"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_13__","metadata":{},"source":["如果你需要使用更特定于你的平台或包管理器的安装方法，你可以在[这里](https://pytorch.org/get-started/locally/)查看更完整的安装说明。\n","\n"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_14__","metadata":{},"source":["#### 1.3 验证 PyTorch 安装并查看版本 <a id='1-3'></a>\n","\n","安装 PyTorch 后，确认库已成功安装并且你可以开始使用它。 \n","\n","不要跳过此步骤。 \n","\n","如果 PyTorch 未正确安装或在此步骤中引发错误，则将无法运行之后的示例。"]},{"cell_type":"code","execution_count":47,"id":"__bohr_old_version_cellId_15__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.13.1+cu117\n"]}],"source":["import torch\n","print(torch.__version__)  # torch.__version__ 返回安装的 PyTorch 的版本号"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_16__","metadata":{},"source":["### 2 PyTorch 深度学习模型的建立范式 <a id='pytorchdeeplearningmodellife-cycle'></a>\n","\n","在本节中，你将了解深度学习模型的建立范式以及可用于定义模型的 PyTorch API。 \n","\n","建立模型有一个范式，这个非常简单的知识为数据建模和理解 PyTorch API 提供了支撑。 \n","\n","模型建立范式中的五个步骤如下： \n","\n","1. 准备数据。 \n","2. 定义模型。 \n","3. 训练模型。 \n","4. 评估模型。 \n","5. 做出预测。 \n","\n","注意：使用 PyTorch API 有很多方法可以实现这些步骤，我们的目标是向你展示最简单、最常见或最惯用的方法。 \n","\n","如果你发现更好的方法，请通过邮箱告诉我。\n","\n","接下来让我们依次仔细看看每个步骤。 \n","\n",">在本节中，我们将以 **基于鸢尾花数据集的多分类感知机** 为例进行介绍。\n",">\n",">这个问题涉及在给定花的测量值的情况下预测鸢尾花的种类。\n",">\n",">数据集将使用 Pandas 自动下载，但您可以在此处了解更多信息：\n",">\n","> - [Iris Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv).\n","> - [Iris Dataset Description](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.names)."]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_17__","metadata":{},"source":["#### 2.1 准备数据 <a id='2-1'></a>\n","\n","\n","第一步是加载和准备数据。 \n","\n","神经网络模型需要输入数据和输出数据。 \n","\n","你可以使用标准 Python 库来加载和准备多维数据，例如 CSV 文件。\n","\n","Pandas 可用于加载你的 CSV 文件，Scikit-Learn 中的工具可用于编码分类数据，例如对标签分类。\n","\n","PyTorch 提供了 Dataset 类，你可以扩展和自定义该类以加载你的数据集。 \n","\n","例如，数据集对象的构造函数可以加载你的数据文件（例如 CSV 文件）。然后，你可以覆盖可用于获取数据集长度（行数或样本数）的 `__len__()` 函数，以及用于按索引获取特定样本的 `__getitem__()` 函数。 \n","\n","加载数据集时，你还可以执行任何所需的转换，例如缩放或编码。 \n","\n","下面提供了自定义数据集类的框架。"]},{"cell_type":"code","execution_count":49,"id":"__bohr_old_version_cellId_18__","metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from torch.utils.data import Dataset\n","from torch.utils.data import random_split\n","\n","# 定义数据集\n","class CSVDataset(Dataset):\n","    # 导入数据集\n","    def __init__(self, path):\n","        # 导入传入路径的数据集为 Pandas DataFrame 格式\n","        df = pd.read_csv(path, header=None)\n","        # 设置神经网络的输入与输出\n","        self.X = df.values[:, :-1]  # 根据你的数据集定义输入属性\n","        self.y = df.values[:, -1]  # 根据你的数据集定义输出属性\n","        # 确保输入的数据是浮点型\n","        self.X = self.X.astype('float32')\n","        # 使用浮点型标签编码原输出\n","        self.y = LabelEncoder().fit_transform(self.y)\n"," \n","    # 定义获得数据集长度的方法\n","    def __len__(self):\n","        return len(self.X)\n"," \n","    # 定义获得某一行数据的方法\n","    def __getitem__(self, idx):\n","        return [self.X[idx], self.y[idx]]\n","    \n","    # 在类内部定义划分训练集和测试集的方法，在本例中，训练集比例为 0.67，测试集比例为 0.33\n","    def get_splits(self, n_test=0.33):\n","        # 确定训练集和测试集的尺寸\n","        test_size = round(n_test * len(self.X))\n","        train_size = len(self.X) - test_size\n","        # 根据尺寸划分训练集和测试集并返回\n","        return random_split(self, [train_size, test_size])"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_19__","metadata":{},"source":["让我们运行一下定义的 *CSVDataset()* 类中的各方法以加深理解"]},{"cell_type":"code","execution_count":50,"id":"__bohr_old_version_cellId_20__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["输入矩阵的形状是：(150, 4)\n"]}],"source":["# 定义数据集路径（在本例中，数据集需为 csv 文件）\n","data_path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n","# 实例化数据集\n","dataset = CSVDataset(data_path)\n","print(f'输入矩阵的形状是：{dataset.X.shape}')\n","# dataset.X  # 查看输入矩阵 dataset.X"]},{"cell_type":"code","execution_count":51,"id":"__bohr_old_version_cellId_21__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["输出矩阵的形状是：(150,)\n"]}],"source":["print(f'输出矩阵的形状是：{dataset.y.shape}')\n","# dataset.y  # 查看输出矩阵"]},{"cell_type":"code","execution_count":52,"id":"__bohr_old_version_cellId_22__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["150\n","150\n"]}],"source":["# len() 方法本质上是调用类内部的 __len__() 方法，所以以下方法是等效的。\n","print(len(dataset))\n","print(dataset.__len__())"]},{"cell_type":"code","execution_count":53,"id":"__bohr_old_version_cellId_23__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[array([5.9, 3. , 5.1, 1.8], dtype=float32), 2]\n","[array([5.9, 3. , 5.1, 1.8], dtype=float32), 2]\n"]}],"source":["# dataset[] 方法本质上是调用类内部的 __getitem__ 方法，所以以下方法是等效的。\n","print(dataset[149])\n","print(dataset.__getitem__(149))"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_24__","metadata":{},"source":["加载后，PyTorch 提供 *DataLoader* 类，用于在模型训练和评估期间导航数据集实例。 \n","\n","可以为训练数据集、测试数据集甚至验证数据集创建 *DataLoader* 实例。 \n","\n","`random_split()` 函数可用于将数据集拆分为训练集和测试集。\n","\n","拆分后，将数据集中 *batch* 及其 *size* 提供给 *DataLoader*，并可选择是否应在每个 *epoch* 对数据进行随机排序。 \n","\n","> 了解什么是 epoch 和 batch，推荐阅读：[训练神经网络中最基本的三个概念：Epoch, Batch, Iteration](https://zhuanlan.zhihu.com/p/29409502)"]},{"cell_type":"code","execution_count":54,"id":"__bohr_old_version_cellId_25__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["划分的训练集的数据类型是：<class 'torch.utils.data.dataset.Subset'>\n","划分的训练集长度是：100\n"]}],"source":["from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","\n","...\n","# 确定训练集和测试集的尺寸\n","n_test = 0.33  # 在本例中，训练集比例为 0.67，测试集比例为 0.33\n","test_size = round(n_test * len(dataset.X))\n","train_size = len(dataset.X) - test_size\n","\n","# 根据尺寸划分训练集和测试集并返回\n","train, test = random_split(dataset, [train_size, test_size])\n","\n","# 让我们查看一下创建的训练集的类型和长度\n","print(f'划分的训练集的数据类型是：{type(train)}')\n","print(f'划分的训练集长度是：{len(train)}')"]},{"cell_type":"code","execution_count":55,"id":"__bohr_old_version_cellId_26__","metadata":{},"outputs":[],"source":["# list(train)  # 查看一下划分的训练集\n","\n","# 你可以用同样的方法查看一下划分得到的测试集"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_27__","metadata":{},"source":["例如，我们可以通过传入数据集中的选定行来定义 *DataLoader*。"]},{"cell_type":"code","execution_count":56,"id":"__bohr_old_version_cellId_28__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100 50\n"]}],"source":["# 为训练集和测试集创建 DataLoader\n","train_dl = DataLoader(train, batch_size=32, shuffle=True)\n","test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n","print(len(train_dl.dataset), len(test_dl.dataset))"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_29__","metadata":{},"source":["定义后，可以循环 *DataLoader*，每次迭代生成一批样本。"]},{"cell_type":"code","execution_count":57,"id":"__bohr_old_version_cellId_30__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["第 0 个 batch 有 32 个数据，其中输入矩阵的形状是 torch.Size([32, 4])，输出矩阵的形状是 torch.Size([32])\n","第 1 个 batch 有 32 个数据，其中输入矩阵的形状是 torch.Size([32, 4])，输出矩阵的形状是 torch.Size([32])\n","第 2 个 batch 有 32 个数据，其中输入矩阵的形状是 torch.Size([32, 4])，输出矩阵的形状是 torch.Size([32])\n","第 3 个 batch 有 4 个数据，其中输入矩阵的形状是 torch.Size([4, 4])，输出矩阵的形状是 torch.Size([4])\n","共有 4 个 batches\n"]}],"source":["# 在本例中，train_dl 的 batch_size 为 32，数据将随机排序。让我们来查看一下 train_dl\n","n_inputs = len(train_dl)\n","for i, (inputs, targets) in enumerate(train_dl):  \n","    print(f'第 {i} 个 batch 有 {len(inputs)} 个数据，其中输入矩阵的形状是 {inputs.shape}，输出矩阵的形状是 {targets.shape}')\n","print(f'共有 {n_inputs} 个 batches')"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_31__","metadata":{},"source":["> enumerate() 函数是 Python 内置函数，用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个有索引的序列，同时列出数据和数据下标。多用在 for 循环中。\n","> \n","> 尝试在本 Notebook 中运行以下示例并理解 enumerate() 函数。"]},{"cell_type":"code","execution_count":58,"id":"__bohr_old_version_cellId_32__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(1, ('Spring', 'Green')), (2, ('Summer', 'Red')), (3, ('Fall', 'Yellow')), (4, ('Winter', 'White'))]\n","--------\n","My impression 1 about Spring is Green.\n","My impression 2 about Summer is Red.\n","My impression 3 about Fall is Yellow.\n","My impression 4 about Winter is White.\n"]}],"source":["seasons = [('Spring', 'Green'), \n","           ('Summer', 'Red'), \n","           ('Fall', 'Yellow'), \n","           ('Winter', 'White')\n","           ]\n","print(list(enumerate(seasons, start=1)))  # start 参数设置序列从 1 开始，不填则默认从 0 开始\n","print('--------')\n","\n","# 再在 for 循环中看看 enumerate 函数的效果\n","for i, (season, color) in enumerate(seasons, start=1):\n","    print(f'My impression {i} about {season} is {color}.')"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_33__","metadata":{},"source":["#### 2.2 定义模型 <a id='2-2'></a>\n","\n","下一步是定义模型。 \n","\n","在 PyTorch 中定义模型的习惯用法是定义一个继承 [Module 类]((https://pytorch.org/docs/stable/nn.html#module))的 *Python class* 。\n","\n","你构造的类定义了模型的层，`forward()` 函数需要覆写以定义在模型层中的输入参数的前向传播。\n","\n","> 了解什么是前向传播，推荐阅读：[笔记 | 什么是Forward Propagation](https://blog.csdn.net/bitcarmanlee/article/details/78819025)\n","\n","许多层都可用，例如用于全连接层的 [Linear](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear)，用于卷积层的 [Conv2d](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d)，用于池化层的 [MaxPool2d](https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d)。\n","\n","激活函数也可以定义为层，例如 [ReLU](https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU), [Softmax](https://pytorch.org/docs/stable/nn.html#torch.nn.Softmax), 和 [Sigmoid](https://pytorch.org/docs/stable/nn.html#torch.nn.Sigmoid).\n","\n","在构造函数中定义给定层后，也可以初始化给定层的权重。 \n","\n","常见的例子包括 [Xavier](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_) 和 [He weight](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_)  权重初始化方案。例如：`xavier_uniform_(self.layer.weight)`\n","\n"," 下面是一个简单的单层 MLP 模型的示例。"]},{"cell_type":"code","execution_count":59,"id":"__bohr_old_version_cellId_34__","metadata":{},"outputs":[],"source":["from torch.nn import Linear\n","from torch.nn import ReLU\n","from torch.nn import Softmax\n","from torch.nn import Module\n","from torch.nn.init import kaiming_uniform_\n","from torch.nn.init import xavier_uniform_\n","\n","# 定义模型\n","class MLP(Module):\n","    # 定义模型属性\n","    def __init__(self, n_inputs):\n","        super(MLP, self).__init__()\n","        # 输出层\n","        self.hidden1 = Linear(n_inputs, 10)\n","        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n","        self.act1 = ReLU()\n","        # 第二个隐藏层\n","        self.hidden2 = Linear(10, 8)\n","        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n","        self.act2 = ReLU()\n","        # 第三层\n","        self.hidden3 = Linear(8, 3)\n","        xavier_uniform_(self.hidden3.weight)\n","        self.act3 = Softmax(dim=1)\n"," \n","    # 前向传播方法\n","    def forward(self, X):\n","        # 输入到第一个隐藏层\n","        X = self.hidden1(X)\n","        X = self.act1(X)\n","        # 第二个隐藏层\n","        X = self.hidden2(X)\n","        X = self.act2(X)\n","        # 输出层\n","        X = self.hidden3(X)\n","        X = self.act3(X)\n","        return X\n"," "]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_35__","metadata":{},"source":["#### 2.3 训练模型 <a id='2-3'></a>\n","\n","训练过程要求你定义 **损失函数** 和 **优化算法** 。\n","\n","常见的损失函数包括：\n","- [BCELoss](https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss): 用于二元分类的 **二元交叉熵损失** (Binary Cross-Entropy Loss)\n","- [CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss): 用于多元分类的 **多元交叉熵损失** (Categorical Cross-Entropy Loss)\n","- [MSELoss](https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss): 用于回归的 **均方损失** (Mean squared loss)\n","\n","> 有关损失函数的更多信息，请参阅教程：\n",">\n","> [用于训练深度学习神经网络的损失和损失函数](https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/)\n","\n","使用 **随机梯度下降** 进行优化，标准算法由 [SGD class](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) 提供，该算法的其他版本也可用，例如 [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam)。\n","\n","> 了解随机梯度下降，请参阅：[如何理解随机梯度下降（stochastic gradient descent，SGD）？](https://www.zhihu.com/question/264189719/answer/932262940)"]},{"cell_type":"code","execution_count":60,"id":"__bohr_old_version_cellId_36__","metadata":{},"outputs":[],"source":["from torch.optim import SGD\n","from torch.nn import CrossEntropyLoss\n","\n","...\n","model = MLP(n_inputs=n_inputs)\n","# 定义优化器\n","criterion = CrossEntropyLoss()\n","optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_37__","metadata":{},"source":["训练模型涉及枚举训练数据集的 *DataLoader*。\n","\n","首先，需要为大量的 *training epochs* 建立一个循环。然后，需要为每个 *mini-batch* 建立一个内部循环，用于随机梯度下降。\n","\n","模型的每次更新都涉及相同的常规模式，包括： \n","\n","- 清除最后一个误差梯度。 \n","- 前向传播并计算模型输出。 \n","- 计算模型输出的损失。 \n","- 通过模型反向传播误差。 \n","- 更新模型以减少损失。\n","\n","例如：\n","\n","```python\n","...\n","# 梯度清除\n","optimizer.zero_grad()\n","# 计算模型输出\n","yhat = model(inputs)\n","# 计算损失\n","loss = criterion(yhat, targets)\n","# 贡献度分配\n","loss.backward()\n","# 升级模型权重\n","optimizer.step()\n","```"]},{"cell_type":"code","execution_count":70,"id":"__bohr_old_version_cellId_38__","metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"expected scalar type Long but found Int","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14644\\2209911533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# 计算损失\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m# 贡献度分配\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\11234\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\11234\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\11234\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3026\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Int"]}],"source":["...\n","# 枚举 epochs\n","for epoch in range(500):\n","    # 枚举 mini-batches\n","    for i, (inputs, targets) in enumerate(train_dl):\n","        # 梯度清除\n","        optimizer.zero_grad()\n","        # 计算模型输出\n","        yhat = model(inputs)\n","        # 计算损失\n","        loss = criterion(yhat, targets)\n","        # 贡献度分配\n","        loss.backward()\n","        # 升级模型权重\n","        optimizer.step()"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_39__","metadata":{},"source":["#### 2.4 评估模型 <a id='2-4'></a>\n","\n","模型拟合后，可以在测试数据集上对其进行评估。 \n","\n","可以通过使用测试集的 *DataLoader* 收集测试集的预测值，然后比较模型预测值与测试集的预期值并计算评价指标。"]},{"cell_type":"code","execution_count":71,"id":"__bohr_old_version_cellId_40__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.3\n"]}],"source":["from numpy import vstack\n","from numpy import argmax\n","from sklearn.metrics import accuracy_score    \n","\n","predictions, actuals = list(), list()  # 实例化预测值列表和预期值列表\n","        \n","for i, (inputs, targets) in enumerate(test_dl):\n","    # 在测试集上评估模型\n","    yhat = model(inputs)\n","    # 转化为 numpy 数据类型\n","    yhat = yhat.detach().numpy()\n","    actual = targets.numpy()\n","    # 转换为类标签\n","    yhat = argmax(yhat, axis=1)\n","    # 为 stack reshape 矩阵\n","    actual = actual.reshape((len(actual), 1))\n","    yhat = yhat.reshape((len(yhat), 1))\n","    # 保存数据\n","    predictions.append(yhat)\n","    actuals.append(actual)\n","\n","predictions, actuals = vstack(predictions), vstack(actuals)\n","# 计算准确度\n","acc = accuracy_score(actuals, predictions)\n","print(acc)"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_41__","metadata":{},"source":["#### 2.5 做出预测 <a id='2-5'></a>\n","\n","拟合模型可用于对新数据进行预测。 \n","\n","例如，您可能有单个图像或一行数据，并且想要进行预测。\n","\n","这需要您将数据包装在 [PyTorch Tensor](https://pytorch.org/docs/stable/tensors.html) 数据结构中。\n","\n","Tensor 只是用于保存 NumPy 数组类型的数据的 PyTorch 版本。它还允许您在模型图中执行自动微分任务，例如在训练模型时调用 `backward()`。 \n","\n","预测也将是一个 Tensor，尽管您可以通过在自动微分图中[分离张量](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.detach)并调用 NumPy 函数来检索 NumPy 数组。\n"]},{"cell_type":"code","execution_count":72,"id":"__bohr_old_version_cellId_42__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["各标签可能的概率： [[4.4664016e-04 9.6045893e-01 3.9094411e-02]] (最可能的种类：class=1)\n"]}],"source":["from torch import Tensor\n","\n","...\n","row = [5.1,3.5,1.4,0.2]\n","# 将数据转化为 Tensor\n","row = Tensor([row])\n","# 做出预测\n","yhat = model(row)\n","# 重写为 Numpy Array 格式\n","yhat = yhat.detach().numpy()\n","\n","print(f'各标签可能的概率： {yhat} (最可能的种类：class={argmax(yhat)})')"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_43__","metadata":{},"source":["现在我们已经充分熟悉了 PyTorch API 和模型建立范式，让我们看看如何从头开始开发一些标准的深度学习模型。\n","\n","有关该节示例的连续代码，请见 [3.2 建立多分类任务的多层感知机模型](#3-2)"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_44__","metadata":{},"source":["### 3 为预测任务建立 PyTorch 深度学习模型 <a id='developpytorchdeeplearningmodels'></a>\n","\n","在本节中，你将了解如何使用标准深度学习模型（包括多层感知器 （Multi Layer Perceptrons, MLP） 和卷积神经网络 （Convolutional Neural Networks, CNN））进行开发、评估和预测。\n","\n","多层感知机模型（MLP）是一种标准的全连接神经网络模型。 \n","\n","它由节点层组成，其中每个节点连接到前一层的所有输出，每个节点的输出连接到下一层节点的所有输入。 \n","\n","MLP 是具有一个或多个完全连接层的模型。此模型适用于表格类型的数据。你可能想使用 MLP 探索三个预测建模问题;它们是二元分类、多类分类和回归。让我们在真实数据集上为每种情况拟合一个模型。 \n","\n","注意：本节中的模型有效，但未优化。看看你是否可以提高他们的表现。<span style='color:orange; font-weight:bold'>不要犹豫，试试直接在 Bohrium Notebook 中实现你的想法。</span>"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_45__","metadata":{},"source":["#### 3.1 建立二分类任务的多层感知机模型 <a id='3-1'></a>\n","\n","我们将使用电离层二分类数据集来演示用于二分类的 MLP。 \n","\n","该数据集涉及预测大气中是否存在给定雷达回波的结构。 \n","\n","数据集将使用 Pandas 自动下载，但你可以在此处了解更多信息：\n","\n","- [Ionosphere Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv).\n","- [Ionosphere Dataset Description](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.names).\n","\n","我们将使用 [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) 将字符串标签编码为整数值 0 和 1。该模型将适合 67% 的数据，其余 33% 将用于评估，使用 [train_test_split() function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) 函数进行拆分。 \n","\n","使用带有 *“He Uniform”* 权重初始化的 *“relu”* 激活函数是一个很好的做法。这种组合对于克服训练深度神经网络模型时[梯度消失](https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/) 的问题大有帮助。有关 ReLU 的更多信息，请参阅教程： \n","\n","- [A Gentle Introduction to the Rectified Linear Unit (ReLU)](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)\n","\n","该模型使用随机梯度下降进行优化，并力求最小化[二元交叉熵损失](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)。 下面列出了完整的示例。"]},{"cell_type":"code","execution_count":79,"id":"__bohr_old_version_cellId_46__","metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkEAAAHeCAYAAACc3N+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABG9klEQVR4nO3deVzVVf7H8fdF4IIgoKiAG2puWZm7opZmqKm55JJaFpplFjklNZVZ2rRhWWPbpOWYVqamlZaVlTmp5b7b5paaGkLSiLhekXt+f/TzjtcvKOCFe+W+nvP4PmY433PP93M1x0+fs3xtxhgjAAAAPxPg7QAAAAC8gSQIAAD4JZIgAADgl0iCAACAXyIJAgAAfokkCAAA+CWSIAAA4JdIggAAgF8iCQIAAH6JJAjIw5o1a2Sz2WSz2fTUU095OxzkY8GCBWrfvr0iIiIUERGhDh066PPPPy/SWGlpabrvvvtUp04d2e12lS1bVo0aNdK4ceN05MgRS/+aNWu6/hnJ76pdu3aez3r//ffVtm1blStXTuHh4WrRooWmTJkiDvAHSpaN12YAViNHjtTrr78uSapXr562bdvm5YhwrpdfflmjRo1SYGCgEhMTZbfb9fXXX+vEiRN67bXXdN999xV4rB07dqht27Y6ePCgatasqaZNm+rkyZNasWKFsrKy1LBhQ61YsUKRkZGuzzz00EPKzMzMc7ylS5dqz549uv322/XOO++43bvnnns0efJkBQcHKyEhQWFhYa7nJCUlafr06UX69QBQBAaAm1OnTpmKFSsaSSY2NtZIMqtWrfJ2WDjL1q1bTZkyZYzdbjcrVqxwtW/bts1ER0ebwMBAs2PHjgKPd9NNNxlJ5t577zWnT592tWdlZZnWrVsbSWbs2LEFGis3N9fExcUZSWbRokVu9z788EMjyZQvX96sW7fO1Z6WlmauvPJKI8nMnDmzwHEDuDhMhwHn+PLLL5WZmam2bdvq3nvvlSS99957Xo4KZ3vllVeUm5urESNGKCEhwdVer149jRkzRqdPn9Yrr7xS4PGWLVsmSXriiSdUpkwZV3tkZKQefvhhSdLatWsLNNbixYt14MABVa1aVR07dnS7N2nSJEl/VZGaNWvmao+Li9M///lPSdILL7xQ4LgBXBySIOAcM2bMkCQNHjxYgwcPliR98MEHysnJyfczv/zyi4YNG6aaNWvKbrercuXKatu2rV588UWdPn3arW9OTo4mT56sdu3aKSoqSqGhoapTp46GDh2q9evXu/pNnz5dNptNTz75ZJ7P7NChg2w2m/bs2eNq27Nnj2w2mzp06KDs7GylpKSoVq1aCgoK0gMPPCBJysrK0muvvaYuXbooPj5edrtd0dHRuuGGG7Ro0aJ8v2NB4v7www9ls9l0yy235DvO8OHDZbPZNG3atHz7XMiZdT/9+vWz3DvTtmDBggKPZ7fbL9gnOjq6QGOd+efnlltuUUCA+//Fnvl16tChg+Vz7du3V0BAgDZt2qS9e/cW6FkALpK3S1GAL8nKyjIhISEmODjY/Pnnn8YYY9q0aWMkmU8//TTPz8yZM8fY7XYjyVx++eVmwIAB5oYbbjDVq1c3ksyhQ4dcfY8ePWquvfZaI8mEhYWZLl26mAEDBphWrVqZoKAgc//997v6Tps2zUgy48aNy/O57du3N5LM7t27XW27d+82kkzLli1N48aNTfny5U3v3r1Nnz59zJNPPmmMMWbhwoVGkqlZs6bp1KmTGTBggElISDA2m83YbDYzdepUy7MKGvepU6dMbGyssdvtJjMz0zLOkSNHTHh4uImIiDDHjh1z+x7Tpk3L53fF3aFDh4wkI8kcPXo0zz5npjMPHz5coDGHDBlywemw//znPxcc5/jx46ZcuXJGktm8ebPlflBQkJFkfv755zw/HxERcd5/1gB4FkkQcJZ///vfRpLp1auXq+2NN94wkkz//v0t/bdv325CQkJMYGCgef/9993uOZ1O89VXX5mTJ0+62oYNG2YkmWuvvdb88ccfbv3T09Pd1h5dTBIkySQkJLglYGfs2rXLrFy50tK+YcMGExUVZSIiIsyRI0fc7hUm7scee8xIMhMnTrQ8Y8qUKUaSueeeeyzfo6BJ0ObNm13ravLTuHFjI8ls2bKlQGMeOHDAXHXVVa7ksG/fvqZ79+4mKirKxMbGmhkzZhRonJkzZxpJplGjRnner1KlipFkFi5caLn3559/un7vXnvttQI9D8DFIQkCznLmL+S5c+e62jIzM01QUJAJCQkxWVlZbv3vueceI8mMGDHigmP//vvvrsW8e/bsuWD/i02C1q5de8FnnGvMmDGWSkRh496zZ48JCAgwDRs2tNxr1aqVkWQ2bNjgarvttttM/fr1zccff1ygGJcvX24kmapVq+bbp23btkaSWb58eYHGNOavJKRz586uX78zV58+fcwvv/xSoDG6du1qJJkJEybkeX/gwIFGkhkwYIDl3oQJE1zPfO655wocN4CiC/Tk1BpwKdu7d6+WLVumqKgo9ejRw9UeHR2tbt266ZNPPtHcuXN15513uu598803kqS77777guMvWbJEubm5uvHGGxUfH+/5L3CWuLg4NW/ePN/7ubm5Wrx4sVasWKEDBw7I4XBI+mur+Nn/XZS44+PjdcMNN+iLL77QihUr1KZNG0nSDz/8oNWrV6t58+Zq0qSJq/+7775bpO/oSVu2bFH37t1VpkwZffLJJ7r22mt17Ngxffjhhxo9erSWLFmiFStWqH79+vmO8ccff2jRokUKCAjId03UQw89pA8//FAffPCBatSoofvuu09ly5bVRx99pLFjxyowMFCnT5+2rCUCUDxIgoD/9/7778sYo379+lkWyg4ePFiffPKJZsyY4ZYE7du3T5J02WWXXXD8wvS9WDVq1Mj33v79+3XjjTdq8+bN+fY5+3DAosQ9YsQIffHFF5oyZYorCZoyZYok6a677irwOHkJDw+XJB0/fjzfPseOHZMklStX7oLj5eTkqF+/fkpLS9PatWvVtGlTSVJUVJTuv/9+5ebm6sEHH9TYsWP1wQcf5DvO7Nmzdfr0aXXq1ElVqlTJs0+zZs00bdo03XXXXZowYYImTJjgute9e3cFBQVp/vz5Kl++/AXjBnDx+NcN4P+d2Qa/ZMkStWvXzu06s2152bJl+u2337wZpovT6cz3XkhISL737rzzTm3evFl9+/bV6tWrlZWVpdzcXBlj9Oabb0rSRZ9c3K1bN1WvXl1z5sxRdna2Tp48qRkzZig8PFyDBg26qLHPJHiHDh1yJTvn2r9/vyQVqHK1atUq7dixQ7Vq1XIlQGfr37+/pP9to8/P2bsKz2fw4MHauXOn/vnPf2rEiBF64IEHtGDBAi1YsEAHDx6UJF1xxRUXjBvAxaMSBOivrcu//PKLJGnnzp3auXNnnv2MMXr//ff12GOPSZKqV6+uHTt26Ndff1Xjxo3P+4zq1atLkn799dcCxRQcHCxJOnr0aJ73z1RoCuPYsWNatGiRYmJi9MEHH7idiSNJu3btsnymsHFLUpkyZXTXXXdp7Nixev/99xUREaFDhw7pzjvvLFB15nyioqJUo0YN7d27Vxs3blS7du3c7u/bt0+ZmZmKj49XRETEBcc7kzCdfRr02c60Hzp0KN8xtm/frrVr16ps2bLq06fPBZ9ZtWpVjRo1yq3txIkT2rRpk8qVK5dnMgbA86gEAfrfv8U/9NBDMn9tGLBcS5YscesrSYmJiZKkt95664LP6NChg8qUKaOvvvqqQAlMXFycpL/+gj3X9u3bi3SWzOHDh+V0OhUXF2dJgHJycjRv3ryLjvuMO++8U4GBgZoyZYrHpsLO6N69u6S/ziU615m2s9d1nU9sbKwkadu2bXm+I+zMIYk1a9bMd4wz/0zcdNNNrum6wnr77bd17Ngx3XbbbQoNDS3SGAAKyVsrsgFfcfr0aRMTE2MkmfXr1+fbLzc311StWtVIcr3yYNu2ba4t8rNnz3br73Q6zddff+22RX7o0KFGkrnuuuss5+hkZGS4bTU/cuSIKVu2rAkMDHR7xcLBgwfNNddc49pJlNfusPbt2+f5HXJyckxkZKQJDAw033//vduvwahRo1xjnrsjrTBxn61Pnz6uMfPbNl7Y3WHGuL824+zt/tu3b8/3tRn79+839evXN/Xr13drP3HihKlcubKRZG6//Xa336/ff//dtXV+zJgx+cZTu3ZtI8l8+eWXF4w9r1178+fPN2XLljUVK1Y0Bw8evOAYADyDJAh+74svvjCSTL169S7YNyUlxUhyO9Rw1qxZrkPwGjZsaAYOHGi6du2a52GJ2dnZrsMXw8LCTNeuXc2AAQNM69atTXBwsNu4xhgzduxYI8mEhISYLl26mBtuuMGUL1/etGnTxiQkJBQ6CTLGmGeffdZIMmXKlHEdllizZk0TGhpqkpOT80yCChv3GV9//bUrCXr99dfz7FPYc4LO+Oc//2kkmcDAQNO1a1fTq1cvExoaaiSZV1991dL/7OMDzjVv3jwTGBjo2nrfq1cv07lzZ9fBh02bNrWcnXTGmS37sbGxbgct5keSueyyy8yNN95oBgwYYK644gojyURHRxfpWAMARUcSBL83aNCg857Hc7a1a9caSaZy5comJyfH1b5582YzePBgU7VqVRMUFGQqV65s2rZta1566SW3fsYY43A4zCuvvGJatmxpwsPDTWhoqLnsssvM0KFDLZUop9NpJkyYYOrUqWOCgoJMtWrVzIMPPmiOHTt23nOCzpcEGWPMO++8Y5o0aWLKli1roqOjTa9evczmzZvPezZRYeI+48SJEyYoKMiEhobmeXCjMUVPgowx5tNPPzXXXHONCQ8PN+Hh4eaaa64xCxYsyLPv+ZIgY/46LPKWW24x1apVM0FBQSYsLMw0btzYPPfcc+b48eP5xnDmrKhRo0YVKOZRo0aZJk2amKioKGO3203dunVNSkqKycjIKNDnAXiOzZiL3AYCAPmYNWuWbrnlFiUlJWn69OneDgcA3JAEASgWOTk5atGihTZv3qw1a9aoRYsW3g4JANywRR6AR3366aeaP3++1qxZo59++km9e/cmAQLgk9giD8CjNmzYoGnTpiktLU233HKLpk6d6u2QACBPTIcBAAC/RCUIAAD4JZIgAADgl0iCAACAX/Kr3WHj48//dmcAF+eZg8u9HQJQqh09vrvEnpWTaX2h8sUIqljbo+N5gl8lQQAAoICcud6OoNgxHQYAAPwSlSAAAGBlnN6OoNiRBAEAACtn6U+CmA4DAAB+iUoQAACwMEyHAQAAv8R0GAAAQOlEJQgAAFgxHQYAAPwShyUCAACUTlSCAACAlR9Mh1EJAgAAVk6nZ69CqFmzpmw2m+VKTk6WJJ08eVLJycmKjo5WeHi4+vbtq4yMjEJ/RZIgAADgU9auXasDBw64rkWLFkmS+vfvL0kaNWqUFixYoLlz52rp0qVKS0tTnz59Cv0cpsMAAICFNw9LrFSpktvP48eP12WXXab27dvr8OHDmjp1qmbOnKmOHTtKkqZNm6bLL79cq1atUuvWrQv8HCpBAADAysPTYQ6HQ9nZ2W6Xw+G4YBinTp3SjBkzdMcdd8hms2n9+vXKyclRYmKiq0+DBg1Uo0YNrVy5slBfkSQIAAAUu9TUVEVGRrpdqampF/zc/PnzlZWVpSFDhkiS0tPTFRwcrKioKLd+MTExSk9PL1RMTIcBAAArD0+HjR49WikpKW5tdrv9gp+bOnWqunbtqipVqng0HokkCAAA5MXDhyXa7fYCJT1n++233/TNN9/o448/drXFxsbq1KlTysrKcqsGZWRkKDY2tlDjMx0GAAB80rRp01S5cmV1797d1dasWTMFBQVp8eLFrrZt27Zp7969SkhIKNT4VIIAAICVlw9LdDqdmjZtmpKSkhQY+L90JTIyUsOGDVNKSooqVKigiIgIjRw5UgkJCYXaGSaRBAEAgLwU8oBDT/vmm2+0d+9e3XHHHZZ7EydOVEBAgPr27SuHw6EuXbrojTfeKPQzbMYY44lgLwXj4wd7OwSgVHvm4HJvhwCUakeP7y6xZzl+WnzhToVgv+J6j47nCVSCAACAlR+8O4wkCAAAWHl5OqwksDsMAAD4JSpBAADAwhjPnhPki0iCAACAlR+sCWI6DAAA+CUqQQAAwMoPFkaTBAEAACumwwAAAEonKkEAAMDKw2+R90UkQQAAwIrpMAAAgNKJShAAALBidxgAAPBLTIcBAACUTlSCAACAFdNhAADAL/lBEsR0GAAA8EtUggAAgIUxHJYIAAD8EdNhAAAApROVIAAAYOUH5wSRBAEAACumwwAAAEonKkEAAMCK6TAAAOCXmA4DAAAonagEAQAAK6bDAACAX2I6DAAAoHSiEgQAAKz8oBJEEgQAAKz8YE0Q02EAAMAvUQkCAABWTIcBAAC/xHQYAABA6UQlCAAAWDEdBgAA/BLTYQAAAKUTlSAAAGDFdBgAAPBLfpAEMR0GAAD8EpUgAABgZYy3Iyh2JEEAAMCK6TAAAIDSiUoQAACw8oNKEEkQAACw4rBEAACAkvX7779r8ODBio6OVmhoqK666iqtW7fOdd8Yo7FjxyouLk6hoaFKTEzUjh07Cv0ckiAAAGDldHr2KqBDhw6pbdu2CgoK0sKFC/Xzzz/rpZdeUvny5V19XnjhBb366quaPHmyVq9erbCwMHXp0kUnT54s1FdkOgwAAFh5eIu8w+GQw+Fwa7Pb7bLb7W5tzz//vKpXr65p06a52mrVqnVWWEYvv/yyHn/8cfXq1UuS9O677yomJkbz58/XwIEDCxwTlSAAAFDsUlNTFRkZ6XalpqZa+n366adq3ry5+vfvr8qVK6tJkyaaMmWK6/7u3buVnp6uxMREV1tkZKRatWqllStXFiomKkEAAMDKw7vDRo8erZSUFLe2c6tAkrRr1y5NmjRJKSkpeuyxx7R27Vr97W9/U3BwsJKSkpSeni5JiomJcftcTEyM615BkQQBAAArDydBeU195f1Yp5o3b67nnntOktSkSRP9+OOPmjx5spKSkjwaE9NhAADAZ8TFxalhw4ZubZdffrn27t0rSYqNjZUkZWRkuPXJyMhw3SsokiAAAGBlnJ69Cqht27batm2bW9v27dsVHx8v6a9F0rGxsVq8eLHrfnZ2tlavXq2EhIRCfUWmwwAAgIVxeucFqqNGjVKbNm303HPP6eabb9aaNWv01ltv6a233pIk2Ww2PfDAA3rmmWdUt25d1apVS0888YSqVKmi3r17F+pZJEEAAMBntGjRQvPmzdPo0aP11FNPqVatWnr55Zd16623uvo8/PDDOnbsmIYPH66srCy1a9dOX375pUJCQgr1LJsxHj4IwIeNjx/s7RCAUu2Zg8u9HQJQqh09vrvEnnV88v0eHa/siFc8Op4nUAkCAABWvDsMAACgdKISBAAArLy0MLokkQQBAAArDx+W6IuYDgMAAH6JShAAALDyg0oQSRAAALDygxN0mA4DAAB+iUoQAACwYjoMKF6t7+2h+je0UIXL4nT65Cn9vn6Hloz/QP/ddcDVJ6pGZXUcc4uqtainMsFB2rV0ixaNe0fHM7O9GDlwaQoICNCYxx/QgIG9FRNTSQcOZOj9GR/p+fGveTs0+Bo/2CLPdBi8qkary7Xh3UV6r/eT+mDw8woICtSA9x5RUKhdkhQUateAGY/IyGjWoOc0o+8/VCaojPpNfVCy2bwcPXDpSXlwhO6881Y9mDJOzZokauzjz+uBUcN1zz1DvB0aUOKoBMGr5iS94Pbz5w++qfs3TlLsVTW1b802VW1eV5HVKmlat8d16ugJV58Htryp+DYN9dvyn7wRNnDJatW6qT77fJG++vJbSdLevb+r/8091Kz51V6ODD7HD16b4ZNJUGZmpt5++22tXLlS6enpkqTY2Fi1adNGQ4YMUaVKlbwcIYqLvVxZSdKJrGOSpMDgIMkY5Z7KcfU57ciRcRpVb1GfJAgopNWrNmjoHYNUp04t7dy5W1dedbkSElro0Uef8XZo8DV+MB3mc0nQ2rVr1aVLF5UtW1aJiYmqV6+eJCkjI0Ovvvqqxo8fr6+++krNmzc/7zgOh0MOh8Ot7bTJVaCtTLHFjotksylx3GDtW7tNmdv3S5J+37hTp4471OHRgVr6whzZbDZ1eHSAAgLLKKxylHfjBS5BL704SeXKhWvDpm+Um5urMmXK6B9Pvqg5H3zi7dCAEudzSdDIkSPVv39/TZ48WbZz1nwYYzRixAiNHDlSK1euPO84qamp+sc//uHWdn3EVUqMauTxmOEZnZ9OUqV61TSj39OuthP/PaL5976qLs8OVfOhnWWcRj9/ulLpP+yW8YOdC4Cn9e3bXQMG9tIdQ+7XL7/s0FWNGur5F57QgQMZmvn+x94ODz7EH/4/1maMb52GFBoaqo0bN6pBgwZ53t+6dauaNGmiEydOnHecvCpBr155N5UgH9XpqdtVt1MzvX/zMzq872CefULLh8uZ65Qj+7juW/u61vx7oda8+XkJR4rzeebgcm+HgAvYun25/vnSZL315nuutocfuU8DB/ZW0yaJXowMBXH0+O4Se9axZ2/36HhhY9716Hie4HOVoNjYWK1ZsybfJGjNmjWKiYm54Dh2u112u92tjQTIN3V66nbV69JcMwc8m28CJEknDh2VJMW3aaiwihHauWhDSYUIlBqhoaFynvNv+Lm5ubIFsFkY/sfnkqCHHnpIw4cP1/r163X99de7Ep6MjAwtXrxYU6ZM0YsvvujlKOEpnZ8ZooY9E/TRXRN16thJhVWKlCQ5so/rtOOvxdBX9b9Wf+78Xcf/PKKqzeoqcdxgrZ36pdtZQgAKZuEXi/X3h5O1b1+afvl5u65ufIVGjhymd9+d6+3Q4GvYHVbykpOTVbFiRU2cOFFvvPGGcnNzJUllypRRs2bNNH36dN18881ejhKe0vS2v8rvt8553K398wff1A8ffidJqlA7Tu0fvlmhUeE6vP+gVrz+qdb+e2GJxwqUBg89+KSeGJuiiS8/rUqVonXgQIbefnuWUp971duhwdf4we4wn1sTdLacnBxlZmZKkipWrKigoKCLGm98/GBPhAUgH6wJAopXia4JeupWj44XNvZ9j47nCT5XCTpbUFCQ4uLivB0GAAD+xw92h/l0EgQAALzED6bD2A4AAAD8EpUgAABgxe4wAADgl5gOAwAAKJ2oBAEAAAt/eHcYlSAAAOCXqAQBAAArP1gTRBIEAACs/CAJYjoMAAD4JSpBAADAinOCAACAX2I6DAAAoHSiEgQAACyMH1SCSIIAAICVHyRBTIcBAAC/RCUIAABY+cFrM0iCAACAFdNhAAAApROVIAAAYOUHlSCSIAAAYGFM6U+CmA4DAAB+iUoQAACwYjoMAAD4JT9IgpgOAwAAfokkCAAAWBin8ehVUE8++aRsNpvb1aBBA9f9kydPKjk5WdHR0QoPD1ffvn2VkZFRpO9IEgQAAKycxrNXIVxxxRU6cOCA6/r+++9d90aNGqUFCxZo7ty5Wrp0qdLS0tSnT58ifUXWBAEAAJ8SGBio2NhYS/vhw4c1depUzZw5Ux07dpQkTZs2TZdffrlWrVql1q1bF+o5VIIAAICV07OXw+FQdna22+VwOPJ89I4dO1SlShXVrl1bt956q/bu3StJWr9+vXJycpSYmOjq26BBA9WoUUMrV64s9FckCQIAABaeXhOUmpqqyMhItys1NdXy3FatWmn69On68ssvNWnSJO3evVvXXHONjhw5ovT0dAUHBysqKsrtMzExMUpPTy/0d2Q6DAAAFLvRo0crJSXFrc1ut1v6de3a1fW/GzVqpFatWik+Pl5z5sxRaGioR2MiCQIAAFYePifIbrfnmfRcSFRUlOrVq6edO3eqU6dOOnXqlLKystyqQRkZGXmuIboQpsMAAICVh9cEFdXRo0f166+/Ki4uTs2aNVNQUJAWL17sur9t2zbt3btXCQkJhR6bShAAAPAZDz30kHr06KH4+HilpaVp3LhxKlOmjAYNGqTIyEgNGzZMKSkpqlChgiIiIjRy5EglJCQUemeYRBIEAADyUJgDDj1p//79GjRokP78809VqlRJ7dq106pVq1SpUiVJ0sSJExUQEKC+ffvK4XCoS5cueuONN4r0LJsxpvS/HOT/jY8f7O0QgFLtmYPLvR0CUKodPb67xJ51qG8Hj45X/qMlHh3PE1gTBAAA/BLTYQAAwMJb02EliSQIAABYXcSOrksF02EAAMAvUQkCAAAWxg8qQSRBAADAiiToL3fccUeRH2Cz2TR16tQifx4AAKA4FCgJmj59epEfQBIEAMClh+mw//ftt98WdxwAAMCXkAT9pX379sUdBwAAQIliYTQAALBgOuwCTp8+rc8//1xr1qxRZmamWrVq5VpEnZaWpszMTDVs2FCBgeRaAABcSkiCzuP777/X4MGDtW/fPhljZLPZlJOT40qCVq5cqZtvvllz585Vnz59PBYwAACAJxTpxOiff/5ZN9xwgw4cOKCRI0dqzpw5Ovdl9D169FDZsmX10UcfeSRQAABQcozTs5cvKlIl6Omnn9bJkyf1xRdfqHPnznn2CQ4OVtOmTbVx48aLChAAAHiBsXk7gmJXpErQt99+q5YtW+abAJ1RtWpVpaWlFSkwAACA4lSkSlBWVpaqV69+wX7Hjh1TTk5OUR4BAAC8yFensDypSElQ5cqVtXPnzgv2++WXXwqULAEAAN9inEyH5aljx47atGnTeU+Snjdvnnbu3KlOnToVOTgAAIDiUqQk6NFHH1VwcLB69+6tSZMmKT093XXv0KFDevvttzVs2DCFhYUpJSXFY8ECAICS4Q+7w2zm3L3tBTR//nzddtttOn78eJ73Q0JCNGvWLPXs2fOiAvSk8fGDvR0CUKo9c3C5t0MASrWjx3eX2LN+T+jo0fGqrvyPR8fzhCJVgiSpd+/e+vHHHzVy5Eg1aNBAISEhCg4OVu3atXX33Xdry5YtPpUAAQAAnO2i3mcRHx+vl19+2UOhAAAAX+GrU1iexEu9AACAhT/sDruoJMjhcOijjz7Sd9995zoUsUqVKmrXrp369u2rkJAQjwQJAADgaUVOgr755hsNGTJEBw4csLw37K233tLDDz+s6dOns0UeAIBLUNG2TV1aipQErV69WjfeeKNOnTqlVq1aadCgQapZs6Yk6bffftOsWbO0atUq9ejRQ0uXLlWrVq08GTMAAChmTIfl44knnlBOTo4mTZqku+++23J/5MiReuuttzRixAiNHTtWX3311UUHCgAA4ElF2iK/evVqNW/ePM8E6Izhw4erRYsWWrVqVZGDAwAA3mGcNo9evqhISVBAQIDq1KlzwX516tSRzeabXxwAAOTPGM9evqhISVDLli21ZcuWC/bbsmWLWrZsWZRHAAAAFKsiJUFPP/20duzYoXHjxsnptJ6mZIzRuHHjtGPHDj399NMXHSQAAChZ/jAdVqCF0e+++66lLSkpSc8884zee+899e3bV/Hx8ZL+2h328ccfa8+ePbrrrru0bds2docBAHCJMcY3ExdPKtALVAMCAvJc23P2R8/cP3c4m82m3Nzci43TI3iBKlC8eIEqULxK8gWqv17ZxaPjXfaj7+0UL1AlaOzYsSxwBgDAj/DusP/35JNPFnMYAADAlzj9YDqsSAujAQAALnW8RR4AAFj4w8Loi0qCvv/+e33yySfasWOHjhw5YlkULf21MHrx4sUX8xgAAFDCfHVbuycVKQkyxmjYsGF65513XImPzWaz7BYzxrCgGgAA+KQirQmaPHmypk+frmbNmmnRokXq06ePJGnbtm1auHChhgwZooCAAP3973/Xrl27PBowAAAofv7w2owiVYKmT5+usLAwLVy4UNHR0ZoxY4YkqW7duqpbt666dOmibt26acCAAWrTpo3rIEUAAHBp8IfpsCJVgn755Re1adNG0dHRkv53UOLZhyL269dPzZo104svvuiBMAEAADyrSEmQ0+l0JUCSVLZsWUnSoUOH3PrVrVtXP/zww0WEBwAAvMFpbB69fFGRkqCqVasqLS3N9fOZ6a6NGze69du+fbsCA9mFDwDApcYYm0cvX1SkJKhp06b6+eefXdNfnTt3ljFGDz/8sLZu3aojR45owoQJWr9+vZo0aeLRgAEAADyhSElQz549lZmZqc8//1ySdPXVV2vgwIHavHmzrrjiCkVFRenRRx9VYGCgnn32WY8GDAAAip+v7A4bP368bDabHnjgAVfbyZMnlZycrOjoaIWHh6tv377KyMgo9NhFSoIGDRqkEydOqHv37q62d955R88995xatGihOnXqqFu3blq8eLFatmxZlEcAAAAv8oU1QWvXrtWbb76pRo0aubWPGjVKCxYs0Ny5c7V06VKlpaW5juspjCIv2LHb7W4/BwUF6dFHH9Wjjz5a1CEBAAAkSUePHtWtt96qKVOm6JlnnnG1Hz58WFOnTtXMmTPVsWNHSdK0adN0+eWXa9WqVWrdunWBn8ELVAEAgIWnF0Y7HA5lZ2e7XQ6HI9/nJycnq3v37kpMTHRrX79+vXJyctzaGzRooBo1amjlypWF+o4kQQAAwMLTa4JSU1MVGRnpdqWmpub57NmzZ2vDhg153k9PT1dwcLCioqLc2mNiYpSenl6o71ig6bDatWsXatCz2Ww2/frrr0X+PAAAuPSNHj1aKSkpbm3nLq2RpH379un+++/XokWLFBISUqwxFSgJ2rNnT7EGAQAAfIunDzi02+15Jj3nWr9+vf744w81bdrU1Zabm6tly5bp9ddf11dffaVTp04pKyvLrRqUkZGh2NjYQsVUoCTI6XQWalBf9fiBb70dAlCqnUj7ztshAPAQbx1weP3111veNjF06FA1aNBAjzzyiKpXr66goCAtXrxYffv2lfTXC9z37t2rhISEQj2L45wBAIDPKFeunK688kq3trCwMEVHR7vahw0bppSUFFWoUEEREREaOXKkEhISCrUzTCIJAgAAefDV931J0sSJExUQEKC+ffvK4XCoS5cueuONNwo9js2YiznH8dISGFzV2yEApRrTYUDxCqpY9I1KhbWqSuEPHzyf1mkfe3Q8T2CLPAAA8EtMhwEAAAtfng7zFJIgAABg4a3dYSWJ6TAAAOCXqAQBAACL0nFC4Pl5JAnasWOHMjMzFR0drXr16nliSAAA4EVGTIfly+Fw6LHHHlPFihXVoEEDtWvXTuPHj3fdnzFjhpo2bapNmzZ5Ik4AAACPKlISdOLECXXo0EHPP/+8goOD1a1bN5173FDHjh21efNmzZkzxyOBAgCAkuM0nr18UZGSoBdeeEGrV6/WHXfcoV27dmnBggWWPlWqVFHDhg31zTffXHSQAACgZDll8+jli4qUBH3wwQeqUaOGJk2adN7X3NevX1/79u0rcnAAAADFpUhJ0O7du9W8eXMFBp5/XXVwcLAOHTpUpMAAAID3GNk8evmiIu0OCw0NLVBys3v3bpUvX74ojwAAAF7kD1vki1QJaty4sdatW6eDBw/m22f37t3auHGjWrRoUeTgAAAAikuRkqC77rpLR44c0aBBg5SZmWm5n5WVpTvuuEM5OTkaPnz4RQcJAABKFtNh+Rg0aJAWLFig2bNnq3bt2mrTpo0kafny5erVq5eWLl2q7Oxs3X777brxxhs9GjAAACh+TIedx/vvv6/nn39eISEh+vrrryX9dXL0ggULZLPZ9Oyzz2ratGkeCxQAAMCTbObcUw4LKTc3Vxs2bNCePXvkdDpVrVo1tWjRQsHBwZ6K0WMCg6t6OwSgVDuR9p23QwBKtaCKtUvsWV/EDPToeN0yZnt0PE+46HeHlSlTRi1atGABNAAApYivruPxpCJPhwEAAFzKilQJuuOOOwrc12azaerUqUV5DAAA8BJn6S8EFS0Jmj59+gX72Gw2GWNIggAAuAT56vu+PKlISdC3336bZ7vT6dS+ffv09ddfa/bs2Ro1apR69OhxUQECAAAUhyIlQe3btz/v/dtvv13du3dXUlKSevbsWaTAAACA91zU1vFLRLEtjB40aJCuuOIKPfnkk8X1CAAAUEycHr58UbHuDqtbt67WrVtXnI8AAAAokos+Jyg/TqdTW7ZsUUAAu/ABALjUOG2lf2G0xzOU48ePa9OmTRo0aJB27NhxwfVDAADA9xgPX76oSJWgMmXKXLCPMUaVKlXShAkTivIIAACAYlWkJKh69eqy5VMmCw4OVlxcnNq3b6/k5GRVrlz5ogIEAAAlz1cXM3tSkZKgPXv2eDgMAADgS/zhxOgirQn69NNPtXDhQk/HAgAAUGKKlATddNNNevXVVz0dCwAA8BFO2Tx6+aIiTYdVqlRJ5cuX93QsAADAR/jqji5PKlIlqEOHDlqzZo2M8YdfIgAAUBoVKQl6+umnlZmZqVGjRunkyZOejgkAAHiZ0+bZyxcVaTps1qxZ6tatm1577TXNnj1biYmJqlGjhkJCQix9bTabnnjiiYsOFAAAlBx/2CJvMwWY06pdu7b69++v559/XpIUEBAgm81WoOkwm82m3Nzci4/UAwKDq3o7BKBUO5H2nbdDAEq1oIq1S+xZ06sO9uh4Q36f4dHxPKFAlaA9e/bo4MGDrp+nTZtWbAEBAADv84dVv0WaDktKSvJ0HAAAwIf46joeT+IV7wAAwC8VqRIEAABKN39YGF3gJGjTpk166qmnivSQsWPHFulzAADAO/whCSrQ7rAzu8EKyxjD7jDAj7A7DCheJbk77M1qnt0ddvf+S3R3mCRddtllatu2bXHGAgAAfITxg4XRBU6C2rVrp7fffrs4YwEAAD7CH6bD2B0GAAD8ErvDAACABZUgAADgl4yHr4KaNGmSGjVqpIiICEVERCghIUELFy503T958qSSk5MVHR2t8PBw9e3bVxkZGUX6jiRBAADAZ1SrVk3jx4/X+vXrtW7dOnXs2FG9evXSTz/9JEkaNWqUFixYoLlz52rp0qVKS0tTnz59ivSsAm2RLy3YIg8UL7bIA8WrJLfIv1LDs1vk799b9C3yFSpU0IQJE9SvXz9VqlRJM2fOVL9+/SRJW7du1eWXX66VK1eqdevWhRqXNUEAAMDC02uCHA6HHA6HW5vdbpfdbs/3M7m5uZo7d66OHTumhIQErV+/Xjk5OUpMTHT1adCggWrUqFGkJIjpMAAAUOxSU1MVGRnpdqWmpubZ94cfflB4eLjsdrtGjBihefPmqWHDhkpPT1dwcLCioqLc+sfExCg9Pb3QMVEJAgAAFp6uBI0ePVopKSlubflVgerXr69Nmzbp8OHD+vDDD5WUlKSlS5d6OCKSIAAAkAdPLxi+0NTX2YKDg1WnTh1JUrNmzbR27Vq98sorGjBggE6dOqWsrCy3alBGRoZiY2MLHRPTYQAAwKc5nU45HA41a9ZMQUFBWrx4sevetm3btHfvXiUkJBR6XCpBAADAwumld4eNHj1aXbt2VY0aNXTkyBHNnDlTS5Ys0VdffaXIyEgNGzZMKSkpqlChgiIiIjRy5EglJCQUelG0RBIEAADy4K0To//44w/dfvvtOnDggCIjI9WoUSN99dVX6tSpkyRp4sSJCggIUN++feVwONSlSxe98cYbRXoW5wQB8BjOCQKKV0meEzQ+3rPnBD36W9HPCSouVIIAAICFP1RISIIAAICF0w/SIHaHAQAAv0QlCAAAWHhrYXRJIgkCAAAWpX8yjOkwAADgp6gEAQAAC6bDAACAX/LWidEliekwAADgl6gEAQAAC384J4gkCAAAWJT+FIjpMAAA4KeoBAEAAAt2hwEAAL/kD2uCmA4DAAB+iUoQAACwKP11IJIgAACQB39YE8R0GAAA8EtUggAAgIU/LIwmCQIAABalPwViOgwAAPgpKkEAAMDCHxZGkwQBAAAL4wcTYkyHAQAAv0QlCAAAWDAdBgAA/JI/bJFnOgwAAPglKkEAAMCi9NeBSIIAAEAe/GE6jCQIPqdKlVilPveYbujSUWXLhmjnr3t0550pWr9hi7dDAy45nfsmKS39D0v7wD436vEHk/WPF17VyrUbdTDzvypbNkSNr2yoUffeodrx1b0QLVCySILgU6KiIrVsyXwtWbpCN/YYrIOZf6punVo6lHXY26EBl6TZ/35FTuf/9vns2PWb7nrgMXW+7hpJUsP6ddS983WKi6msw9lH9MbUGRo+aoy+mjtNZcqU8VbY8AHsDgNK2MN/v1f796fpzrtSXG179uzzYkTApa1C+Si3n//93hxVrxqnFk2ukiT179XNda9qXIxGDk9S36R79fuBDNWoVqUkQ4WP4bBEoITdeGNnrV+/RbNnvam0/Zu1ds1XGnbHLd4OCygVcnJy9NnX3+qm7p1ls9ks94+fOKn5n3+talViFRdTyQsRAiWr1FaCHA6HHA6HW5sxJs8/+PAdtWvV0N1336aXX5mi8c+/qubNGuvliU/pVE6O3ntvrrfDAy5pi5et1JGjR9W7Wye39tkff6aX3piqEydOqlaNanpr4rMKCgryUpTwFf4wHXZJVoL27dunO+6447x9UlNTFRkZ6XYZ55ESihBFFRAQoI0bf9TjT4zXpk0/6d9T39e/p87U3Xfd5u3QgEvex599pXatm6typWi39u6dr9OH017X9H+9oPjqVfXQ2FQ5HKe8FCV8hfHwf3zRJZkE/fe//9U777xz3j6jR4/W4cOH3S5bQLkSihBFdeDAH/r5l+1ubVu37lT16qxNAC5GWnqGVq3bpL49brDcKxcepvjqVdW88VWa+OwY7f5tnxYvW+GFKIGS5ZPTYZ9++ul57+/ateuCY9jtdtntdrc2psJ834qVa1W/3mVubfXq1tbevb97KSKgdJj3+SJVKB+paxNanrefMUbGSKdO5ZRQZPBV/jAd5pNJUO/evWWz2WRM/uUzEprS6ZVXpui7ZZ/o0UdGau6HC9SiRWPdeeetGnHvw94ODbhkOZ1Ozf98kXp1TVRg4P+2ve/7/YC+XLxMbVo2VYWoSKUfzNTU9+bIbg/WNW1aeDFi+ALnef4OLi18MgmKi4vTG2+8oV69euV5f9OmTWrWrFkJR4WSsG79ZvXrf6eeeeZRPT7mAe3es08pD47TrFnzvB0acMlauXajDmT8oZu6d3ZrtwcHa8PmH/XenPnKPnJU0RWi1PzqKzVj8j8Vfc7WeqA0spnzlVu8pGfPnmrcuLGeeuqpPO9v3rxZTZo0cTsArCACg6t6IjwA+TiR9p23QwBKtaCKtUvsWYPj+3h0vBm/fezR8TzBJytBf//733Xs2LF879epU0fffvttCUYEAIB/4d1hXnLNNdec935YWJjat29fQtEAAIDSyCeTIAAA4F2+eraPJ5EEAQAAC3/YIn9JHpYIAABwsagEAQAAC39YGE0lCAAA+IzU1FS1aNFC5cqVU+XKldW7d29t27bNrc/JkyeVnJys6OhohYeHq2/fvsrIyCj0s0iCAACAhbdeoLp06VIlJydr1apVWrRokXJyctS5c2e3o3NGjRqlBQsWaO7cuVq6dKnS0tLUp0/hzzXyycMSiwuHJQLFi8MSgeJVkocl9onv6dHxPv7t/O8Fzc/BgwdVuXJlLV26VNdee60OHz6sSpUqaebMmerXr58kaevWrbr88su1cuVKtW7dusBjUwkCAADFzuFwKDs72+1yOBwX/Nzhw4clSRUqVJAkrV+/Xjk5OUpMTHT1adCggWrUqKGVK1cWKiaSIAAAYGGM8eiVmpqqyMhItys1NfW8MTidTj3wwANq27atrrzySklSenq6goODFRUV5dY3JiZG6enphfqO7A4DAAAWnt4dNnr0aKWkpLi12e32834mOTlZP/74o77//nuPxnIGSRAAACh2drv9gknP2e677z599tlnWrZsmapVq+Zqj42N1alTp5SVleVWDcrIyFBsbGyhYmI6DAAAWDg9fBWUMUb33Xef5s2bp//85z+qVauW2/1mzZopKChIixcvdrVt27ZNe/fuVUJCQqG+I5UgAABg4a13hyUnJ2vmzJn65JNPVK5cOdc6n8jISIWGhioyMlLDhg1TSkqKKlSooIiICI0cOVIJCQmF2hkmkQQBAAAfMmnSJElShw4d3NqnTZumIUOGSJImTpyogIAA9e3bVw6HQ126dNEbb7xR6GdxThAAj+GcIKB4leQ5Qd1qdPPoeF/s/cKj43kClSAAAGDhDzUSFkYDAAC/RCUIAABYFGZH16WKJAgAAFh4a3dYSWI6DAAA+CUqQQAAwMLTr83wRSRBAADAgt1hAAAApRSVIAAAYMF0GAAA8EvsDgMAACilqAQBAAALpx8sjCYJAgAAFqU/BWI6DAAA+CkqQQAAwILdYQAAwC/5QxLEdBgAAPBLVIIAAICFP7w2gyQIAABYMB0GAABQSlEJAgAAFv7w2gySIAAAYOEPa4KYDgMAAH6JShAAALDwh4XRJEEAAMCC6TAAAIBSikoQAACwYDoMAAD4JX/YIs90GAAA8EtUggAAgIXTDxZGkwQBAAALpsMAAABKKSpBAADAgukwAADgl5gOAwAAKKWoBAEAAAumwwAAgF9iOgwAAKCUohIEAAAsmA4DAAB+iekwAACAUopKEAAAsDDG6e0Qih1JEAAAsHAyHQYAAFA6UQkCAAAWht1hAADAHzEdBgAAUEqRBAEAAAtjjEevwli2bJl69OihKlWqyGazaf78+ZbYxo4dq7i4OIWGhioxMVE7duwo9HckCQIAABZOYzx6FcaxY8d09dVX61//+lee91944QW9+uqrmjx5slavXq2wsDB16dJFJ0+eLNRzWBMEAAB8SteuXdW1a9c87xlj9PLLL+vxxx9Xr169JEnvvvuuYmJiNH/+fA0cOLDAz6ESBAAALIyH/+NwOJSdne12ORyOQse1e/dupaenKzEx0dUWGRmpVq1aaeXKlYUaiyQIAABYeHpNUGpqqiIjI92u1NTUQseVnp4uSYqJiXFrj4mJcd0rKKbDAABAsRs9erRSUlLc2ux2u5ei+QtJEAAAsPD0OUF2u90jSU9sbKwkKSMjQ3Fxca72jIwMNW7cuFBjMR0GAAAsvLlF/nxq1aql2NhYLV682NWWnZ2t1atXKyEhoVBjUQkCAAA+5ejRo9q5c6fr5927d2vTpk2qUKGCatSooQceeEDPPPOM6tatq1q1aumJJ55QlSpV1Lt370I9hyQIAABYFPZsH09at26drrvuOtfPZ9YSJSUlafr06Xr44Yd17NgxDR8+XFlZWWrXrp2+/PJLhYSEFOo5NuMPb0j7f4HBVb0dAlCqnUj7ztshAKVaUMXaJfas8uF1PDreoaM7L9yphLEmCAAA+CWmwwAAgIU/vEWeJAgAAFj4w2oZpsMAAIBfohIEAAAsvLk7rKSQBAEAAAvjB2uCmA4DAAB+iUoQAACwYDoMAAD4JXaHAQAAlFJUggAAgIU/LIwmCQIAABZMhwEAAJRSVIIAAICFP1SCSIIAAIBF6U+BmA4DAAB+ymb8od6FS5LD4VBqaqpGjx4tu93u7XCAUoc/Y/B3JEHwWdnZ2YqMjNThw4cVERHh7XCAUoc/Y/B3TIcBAAC/RBIEAAD8EkkQAADwSyRB8Fl2u13jxo1jwSZQTPgzBn/HwmgAAOCXqAQBAAC/RBIEAAD8EkkQAADwSyRBAADAL5EEwSf961//Us2aNRUSEqJWrVppzZo13g4JKDWWLVumHj16qEqVKrLZbJo/f763QwK8giQIPueDDz5QSkqKxo0bpw0bNujqq69Wly5d9Mcff3g7NKBUOHbsmK6++mr961//8nYogFexRR4+p1WrVmrRooVef/11SZLT6VT16tU1cuRIPfroo16ODihdbDab5s2bp969e3s7FKDEUQmCTzl16pTWr1+vxMREV1tAQIASExO1cuVKL0YGAChtSILgUzIzM5Wbm6uYmBi39piYGKWnp3spKgBAaUQSBAAA/BJJEHxKxYoVVaZMGWVkZLi1Z2RkKDY21ktRAQBKI5Ig+JTg4GA1a9ZMixcvdrU5nU4tXrxYCQkJXowMAFDaBHo7AOBcKSkpSkpKUvPmzdWyZUu9/PLLOnbsmIYOHert0IBS4ejRo9q5c6fr5927d2vTpk2qUKGCatSo4cXIgJLFFnn4pNdff10TJkxQenq6GjdurFdffVWtWrXydlhAqbBkyRJdd911lvakpCRNnz695AMCvIQkCAAA+CXWBAEAAL9EEgQAAPwSSRAAAPBLJEEAAMAvkQQBAAC/RBIEAAD8EkkQAADwSyRBAADAL5EEARdgs9ncroCAAEVFRemaa67Rv//9b3n7vNHp06fLZrPpySefdGsfMmSIbDablixZ4pW4iqpDhw6y2Wzas2dPgfrn9/2LombNmrLZbBc9zoVcqr83QGlDEgQUUFJSkpKSknTrrbeqYcOGWr58ue666y7dcsst3g6t2HgywQAAX8MLVIECOvedSosWLVK3bt00e/Zs3Xrrrbrxxhu9E1g+UlNT9eijj/JCTADIB5UgoIg6deqk2267TZI0f/587waTh7i4ODVo0EBly5b1digA4JNIgoCL0KRJE0nSvn37XG02m001a9bUqVOn9NRTT6lBgway2+3q3bu3q8/x48eVmpqqJk2aKDw8XOHh4WrdurXeeeedfJ+1fPlyJSYmqly5coqKilKXLl20evXqfPufb93JsWPH9Pzzz6t58+aKiIhQWFiYGjRooOTkZG3fvl3SX2tzhg4dKkn6xz/+4bYu6tyq2C+//KIhQ4aoevXqstvtiomJ0cCBA/XTTz/lGVtubq5efPFFNWjQQCEhIapevbruv/9+ZWdn5/t9CuvAgQN64YUX1L59e1WtWlXBwcGKjY1Vnz59tHbt2vN+1hijV155RQ0bNlRISIiqVq2qv/3tb8rKysq3/6xZs9SxY0eVL19eISEhuvzyy/Xkk0/q+PHjHvtOADyL6TDgIhw5ckSSZLfb3dqdTqd69+6tZcuWqX379mrUqJGio6MlSX/88Yc6deqkLVu2KDY2Vu3bt5cxRitWrNCQIUO0bt06vfbaa27jffbZZ7rpppt0+vRptWzZUrVr19bmzZt17bXXasiQIYWK+cCBA+rUqZN++uknlS9fXh06dJDdbteuXbs0efJk1a1bV/Xq1dMNN9yg06dPa/ny5br66qvVuHFj1xh16tRx/e/58+dr4MCBcjgcaty4sVq3bq19+/Zpzpw5WrBggRYuXKhrr73WLYbBgwdr9uzZKlu2rDp37qzAwEC98847Wr58uYKCggr1ffLzySef6JFHHlH9+vXVqFEjRUREaMeOHZo3b54+++wzffbZZ+rcuXOenx05cqTeeustdejQQVdddZWWLl2q1157TUuXLtV3332niIgIV1+n06nBgwdr1qxZCg8PV/PmzVW+fHmtW7dO//jHP7Rw4UItWbJEoaGhHvleADzIADgvSSavPypOp9MkJCQYSWbMmDGW/nXq1DH79++3fK5bt25Gkrn//vvNyZMnXe3p6emmefPmRpJZuHChqz07O9tUqlTJSDJvv/222/MfeeQR1/PGjRvn9pykpCQjyXz77bdu7ddff72RZG6++WZz5MgRt3u7d+82mzdvdv08bdq0PMc+u39YWJgJDw83ixYtcru3cOFCExQUZKpXr24cDoerffbs2UaSqVGjhtm9e7erPSMjw1x55ZWu73P2vfPJL8YtW7aYH3/80dL/yy+/NMHBweayyy4zTqfT7V58fLyRZCIiIsy6detc7UeOHDEdO3Z0/b6d7YUXXjCSTIcOHcyBAwdc7Q6HwwwbNsxIMo888ojbZ/L7vQFQskiCgAs4Nwk6ffq02b59uxkyZIiRZOx2u9m5c6el/9y5cy1jbdy40UgyLVq0MLm5uZb7GzZsMJJMz549XW1vv/22kWSuvfZaS/9Tp06ZatWqFTgJWr16tZFkKleubLKzsy/43S+UBN1///1GknnttdfyvP+3v/3NSDIff/yxq+3aa6+1JHRnLFy40GNJ0PnceuutRpLZsmWLW/uZJOixxx6zfOann34yNpvNhIeHmxMnThhjjMnJyTEVK1Y0YWFhJj093fKZ48ePm9jYWFO+fHm332+SIMA3sCYIKKAz62ECAwNVr149TZ8+XeXKldOsWbN02WWXWfr26NHDMsbXX38tSerdu7cCAqx//M6sEVqzZo2r7bvvvpMkDRw40NI/KChI/fr1K/B3+OabbyRJgwYNUrly5Qr8ufyc+T59+vTJ8/4111wjSa7vk5OTo1WrVkmSBgwYYOl/ww03qHz58hcd1xkOh0OffPKJxowZo+HDh2vIkCEaMmSIfvjhB0nSjh078vxcXr/WDRs21NVXX62jR49q48aNkqQNGzYoMzNTbdq0UUxMjOUzoaGhatasmQ4dOpTvswB4D2uCgAJKSkqSJAUEBCgiIkJXXXWV+vTpk+df2pUrV7asE5LkOgBwzJgxGjNmTL7POnnypOt/p6WlSZLi4+Pz7FuzZs2CfgXXAu5zk7aiOvN9qlatet5+mZmZkqQ///xTp06dUqVKlfLdtRYfH69Dhw5ddGw//PCDevbsed5DF8+s6corhrzUrFlTmzZtcv2enBl70aJFFzxkMTMzU/Xr179w4ABKDEkQUEDn7og6n5CQkDzbnU6nJKldu3YeS0S86cz3OZMg5qdVq1YlEY6LMUY333yz9uzZoxEjRmjEiBGqXbu2wsPDZbPZ9Nhjjyk1NfWiT/s+8/3r1Kmjtm3bnrfvmYXxAHwHSRBQgqpVqybpr+mwBx98sECfiYuLkyT99ttved7Prz0v1atXlyT9+uuvBf7M+VSrVk2//vqrXnrppQL9JR8dHa3g4GAdPHhQJ06cyHPH1N69ey86rq1bt2rr1q1q3ry5Jk2aZLm/a9eu837+t99+01VXXZVnuyRVqVJF0v9+Pxs0aFCoJBmAb2BNEFCCOnXqJEmaN29egT9zZl3NnDlzLPdOnz6tjz76qMBjJSYmSpJmzZqlo0ePXrB/cHCw6zl5Kez3CQoKclWF8vo+X3/9tf773/8WaKzzOTOddiZJOffeokWLzvv5vGLbunWrNm3apPDwcNdxAS1atFBkZKSWLl3qkbgBlCySIKAEtWrVSp06ddLy5cuVnJyc5+GAmzdv1pdffun6uX///oqOjtaSJUvcDlM0xmjcuHGFqpy0bNlS1113nf744w8NHz5cx44dc7u/Z88e16Jh6X8Vj23btuU53oMPPqjQ0FA99NBD+vjjjy33HQ6HPvzwQ+3fv9/Vds8990iSJfbMzEz9/e9/L/B3OZ86deooICBA//nPf9wWJJ88eVIjRoy4YMLy2muvuRY/S38dbjly5EgZYzR06FBXBctut+vhhx/WkSNH1KdPnzwrTL///rvee+89j3wvAB7m3c1pgO9TPucEna9/fHx8vvczMjJMkyZNjCQTFRVlOnToYG655RbTvXt3U7169TzPopk/f74pU6aMkWRatWplBg0aZBo2bGiCgoLMXXfdVahzgvbv32/q169vJJkKFSqYnj17mv79+5umTZuagIAAM3HiRFffEydOmMqVKxtJpn379mbo0KFm2LBhZvny5W6xlS1b1nU2Uo8ePczAgQPNNddcY8LCwowks3HjRrcY+vfvbySZsLAw07NnT9OnTx8TFRVlmjZtalq3bu2RLfJnfl1CQ0NN9+7dTb9+/UxMTIypWLGi63iDadOmuX3mzBb55ORkExQUZLp06WJuvvlmExsbaySZK664wmRlZbl9Jjc319x2221GkgkODjatWrUyAwcONH369DFXXHGFsdls5uqrry7Q7w2AkkUSBFyAp5MgY/5KLl599VXTpk0bExkZaYKDg0316tVN+/btzYQJE8y+ffssn1m2bJm57rrrTFhYmImIiDDXX3+9WbFiRb5JwPn+os3OzjZPPfWUadSokQkNDTXh4eGmQYMG5r777jM7duxw67t27VrTqVMnExkZaWw2W57Jw86dO829995r6tata0JCQky5cuVM/fr1zcCBA82cOXPcDks05q/zdZ5//nlTr149ExwcbKpUqWLuvfdek5WVZdq3b++RJOj06dPmpZdeMg0bNjQhISEmJibG3HrrrWbPnj1m3Lhx502CcnNzzYsvvmgaNGhg7Ha7iYuLM8nJyea///1vvnF88sknpnv37qZy5comKCjIVK5c2TRr1sw8/PDDZv369W59SYIA32Az5iK3RwAAAFyCWBMEAAD8EkkQAADwSyRBAADAL5EEAQAAv0QSBAAA/BJJEAAA8EskQQAAwC+RBAEAAL9EEgQAAPwSSRAAAPBLJEEAAMAvkQQBAAC/9H/5K+jSZz4//gAAAABJRU5ErkJggg==","text/plain":["<Figure size 700x500 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torch import Tensor\n","from torch.nn import Linear, ReLU, Sigmoid, Module, BCELoss\n","from torch.optim import SGD\n","from torch.nn.init import kaiming_uniform_, xavier_uniform_\n","# 绘制混淆矩阵图\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# 定义数据集\n","class CSVDataset(Dataset):\n","    def __init__(self, path):\n","        df = pd.read_csv(path, header=None)\n","        self.X = df.values[:, :-1].astype('float32')\n","        self.y = LabelEncoder().fit_transform(df.values[:, -1]).astype('float32').reshape((len(df.values[:, -1]), 1))\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return [self.X[idx], self.y[idx]]\n","\n","    def get_splits(self, n_test=0.33):\n","        test_size = round(n_test * len(self.X))\n","        train_size = len(self.X) - test_size\n","        return random_split(self, [train_size, test_size])\n","\n","# 定义模型\n","class MLP(Module):\n","    def __init__(self, n_inputs):\n","        super(MLP, self).__init__()\n","        self.hidden1 = Linear(n_inputs, 10)\n","        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n","        self.act1 = ReLU()\n","        self.hidden2 = Linear(10, 8)\n","        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n","        self.act2 = ReLU()\n","        self.hidden3 = Linear(8, 1)\n","        xavier_uniform_(self.hidden3.weight)\n","        self.act3 = Sigmoid()\n","\n","    def forward(self, X):\n","        X = self.hidden1(X)\n","        X = self.act1(X)\n","        X = self.hidden2(X)\n","        X = self.act2(X)\n","        X = self.hidden3(X)\n","        X = self.act3(X)\n","        return X\n","\n","# 准备数据\n","def prepare_data(path):\n","    dataset = CSVDataset(path)\n","    train, test = dataset.get_splits()\n","    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n","    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n","    return train_dl, test_dl\n","\n","# 训练模型\n","def train_model(train_dl, model):\n","    criterion = BCELoss()\n","    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n","    for epoch in range(100):\n","        for i, (inputs, targets) in enumerate(train_dl):\n","            optimizer.zero_grad()\n","            yhat = model(inputs)\n","            loss = criterion(yhat, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","# 评估模型\n","def evaluate_model(test_dl, model):\n","    predictions, actuals = list(), list()\n","    for i, (inputs, targets) in enumerate(test_dl):\n","        yhat = model(inputs)\n","        yhat = yhat.detach().numpy()\n","        actual = targets.numpy()\n","        actual = actual.reshape((len(actual), 1))\n","        yhat = yhat.round()\n","        predictions.append(yhat)\n","        actuals.append(actual)\n","    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n","    acc = accuracy_score(actuals, predictions)\n","    return acc, predictions, actuals\n","\n","# 预测单个数据\n","def predict(row, model):\n","    row = Tensor([row])\n","    yhat = model(row)\n","    yhat = yhat.detach().numpy()\n","    return yhat\n","\n","# 加载数据并训练模型\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n","train_dl, test_dl = prepare_data(path)\n","model = MLP(34)\n","train_model(train_dl, model)\n","\n","# 评估模型并获取混淆矩阵所需数据\n","acc, predictions, actuals = evaluate_model(test_dl, model)\n","cm = confusion_matrix(actuals, predictions)\n","\n","acc, cm\n","\n","# 绘制混淆矩阵图\n","plt.figure(figsize=(7, 5))\n","sns.heatmap(cm, annot=True, fmt='d')\n","plt.title(f'Accuracy: {acc:.3f}', fontsize=15)\n","plt.xlabel('Predicted label', fontsize=15)\n","plt.ylabel('True label', fontsize=15)\n","plt.show()"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_47__","metadata":{},"source":["运行示例后，首先报告训练数据集和测试数据集的长度，然后拟合模型并在测试数据集上对其进行评估。最后，对单行数据进行预测。 \n","\n","注意：根据算法或评估过程的随机性质或数值精度的差异，你的[结果可能会有所不同](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)。请考虑运行几次示例并比较平均结果。 \n","\n","你得到了什么结果？ \n","\n","你能改变模型做得更好吗？\n","\n","你可以试着修改代码以直接输出平均结果吗？\n","\n","<span style='color:orange; font-weight:bold'>不要犹豫，试试直接在 Bohrium Notebook 中实现你的想法。</span>\n","\n","在本例中，我们可以看到该模型实现了大约 94% 的分类准确率，然后预测某行数据属于类 1 的概率为 0.99。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_48__","metadata":{},"source":["#### 3.2 建立多分类任务的多层感知机模型 <a id='3-2'></a>\n","\n","我们将使用鸢尾花多元分类数据集来演示用于多元分类的 MLP。\n","\n","这个问题涉及在给定花的测量值的情况下预测鸢尾花的种类。\n","\n","数据集将使用 Pandas 自动下载，但您可以在此处了解更多信息：\n","\n","- [Iris Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv).\n","- [Iris Dataset Description](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.names).\n","\n","鉴于它是一个多类分类，模型必须为输出层中的每个类提供一个节点，并使用softmax激活函数。损失函数是交叉熵，它适用于整数编码的类标签（例如，0 表示一个类，1 表示下一个类，等等）。\n","\n","下面列出了在鸢尾花数据集上拟合和评估 MLP 的完整示例。\n"]},{"cell_type":"code","execution_count":80,"id":"__bohr_old_version_cellId_49__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100 50\n"]},{"ename":"RuntimeError","evalue":"expected scalar type Long but found Int","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14644\\3757039110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;31m# 训练模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;31m# 评估模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14644\\3757039110.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_dl, model)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[1;31m# 计算损失\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[1;31m# 贡献度分配\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\11234\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\11234\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\11234\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3026\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Int"]}],"source":["# PyTorch｜建立多分类任务的多层感知机模型\n","from numpy import vstack\n","from numpy import argmax\n","from pandas import read_csv\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score\n","from torch import Tensor\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","from torch.nn import Linear\n","from torch.nn import ReLU\n","from torch.nn import Softmax\n","from torch.nn import Module\n","from torch.optim import SGD\n","from torch.nn import CrossEntropyLoss\n","from torch.nn.init import kaiming_uniform_\n","from torch.nn.init import xavier_uniform_\n"," \n","# 数据集定义\n","class CSVDataset(Dataset):\n","    # 导入数据集\n","    def __init__(self, path):\n","        # 导入传入路径的数据集为 Pandas DataFrame 格式\n","        df = read_csv(path, header=None)\n","        # 设置神经网络的输入与输出\n","        self.X = df.values[:, :-1]\n","        self.y = df.values[:, -1]\n","        # 确保输入数据是浮点型\n","        self.X = self.X.astype('float32')\n","        # 使用浮点型标签编码原输出\n","        self.y = LabelEncoder().fit_transform(self.y)\n"," \n","    # 定义获得数据集长度的方法\n","    def __len__(self):\n","        return len(self.X)\n"," \n","    # 定义获得某一行数据的方法\n","    def __getitem__(self, idx):\n","        return [self.X[idx], self.y[idx]]\n"," \n","    # 在类内部定义划分训练集和测试集的方法，在本例中，训练集比例为 0.67，测试集比例为 0.33\n","    def get_splits(self, n_test=0.33):\n","        # 确定训练集和测试集的尺寸\n","        test_size = round(n_test * len(self.X))\n","        train_size = len(self.X) - test_size\n","        # 根据尺寸划分训练集和测试集并返回\n","        return random_split(self, [train_size, test_size])\n"," \n","# 模型定义\n","class MLP(Module):\n","    # 定义模型属性\n","    def __init__(self, n_inputs):\n","        super(MLP, self).__init__()\n","        # 输入到隐层 1\n","        self.hidden1 = Linear(n_inputs, 10)\n","        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n","        self.act1 = ReLU()\n","        # 隐层 2\n","        self.hidden2 = Linear(10, 8)\n","        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n","        self.act2 = ReLU()\n","        # 隐层 3 和输出\n","        self.hidden3 = Linear(8, 3)\n","        xavier_uniform_(self.hidden3.weight)\n","        self.act3 = Softmax(dim=1)\n"," \n","    # 前向传播\n","    def forward(self, X):\n","        # 输入到隐层 1\n","        X = self.hidden1(X)\n","        X = self.act1(X)\n","        # 隐层 2\n","        X = self.hidden2(X)\n","        X = self.act2(X)\n","        # 输出层\n","        X = self.hidden3(X)\n","        X = self.act3(X)\n","        return X\n"," \n","# 准备数据集\n","def prepare_data(path):\n","    # 导入数据集\n","    dataset = CSVDataset(path)\n","    # 划分训练集和测试集并返回\n","    train, test = dataset.get_splits()\n","    # 为训练集和测试集创建 DataLoader\n","    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n","    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n","    return train_dl, test_dl\n"," \n","# 训练模型\n","def train_model(train_dl, model):\n","    # 定义优化器\n","    criterion = CrossEntropyLoss()\n","    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n","    # 枚举 epochs\n","    for epoch in range(500):\n","        # 枚举 mini batches\n","        for i, (inputs, targets) in enumerate(train_dl):\n","            # 梯度清除\n","            optimizer.zero_grad()\n","            # 计算模型输出\n","            yhat = model(inputs)\n","            # 计算损失\n","            loss = criterion(yhat, targets)\n","            # 贡献度分配\n","            loss.backward()\n","            # 升级模型权重\n","            optimizer.step()\n"," \n","# 评估模型\n","def evaluate_model(test_dl, model):\n","    predictions, actuals = list(), list()\n","    for i, (inputs, targets) in enumerate(test_dl):\n","        # 在测试集上评估模型\n","        yhat = model(inputs)\n","        # 转化为 numpy 数据类型\n","        yhat = yhat.detach().numpy()\n","        actual = targets.numpy()\n","        # 转换为类标签\n","        yhat = argmax(yhat, axis=1)\n","        # 为 stacking reshape 矩阵\n","        actual = actual.reshape((len(actual), 1))\n","        yhat = yhat.reshape((len(yhat), 1))\n","        # 保存\n","        predictions.append(yhat)\n","        actuals.append(actual)\n","    predictions, actuals = vstack(predictions), vstack(actuals)\n","    # 计算准确度\n","    acc = accuracy_score(actuals, predictions)\n","    return acc\n"," \n","# 对一行数据进行类预测\n","def predict(row, model):\n","    # 转换源数据\n","    row = Tensor([row])\n","    # 做出预测\n","    yhat = model(row)\n","    # 转化为 numpy 数据类型\n","    yhat = yhat.detach().numpy()\n","    return yhat\n"," \n","# 准备数据\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n","train_dl, test_dl = prepare_data(path)\n","print(len(train_dl.dataset), len(test_dl.dataset))\n","# 定义网络\n","model = MLP(4)\n","# 训练模型\n","train_model(train_dl, model)\n","# 评估模型\n","acc = evaluate_model(test_dl, model)\n","print('Accuracy: %.3f' % acc)\n","# 进行单个预测\n","row = [5.1,3.5,1.4,0.2]\n","yhat = predict(row, model)\n","print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_50__","metadata":{},"source":["运行示例后，首先报告训练数据集和测试数据集的长度，然后拟合模型并在测试数据集上对其进行评估。最后，对单行数据进行预测。 \n","\n","注意：根据算法或评估过程的随机性质或数值精度的差异，你的[结果可能会有所不同](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)。请考虑运行几次示例并比较平均结果。 \n","\n","你得到了什么结果？ \n","\n","你能改变模型做得更好吗？\n","\n","你可以试着修改代码以直接输出平均结果吗？\n","\n","<span style='color:orange; font-weight:bold'>不要犹豫，试试直接在 Bohrium Notebook 中实现你的想法。</span>\n","\n","在本例中，我们可以看到该模型实现了大约 98% 的分类准确率，然后预测了其中一行属于某个类的概率，类 0 的概率最高。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_51__","metadata":{},"source":["#### 3.3 建立回归任务的多层感知机模型 <a id='3-3'></a>\n","\n","\n","我们将使用波士顿房价回归数据集来演示用于回归预测建模的 MLP。 \n","\n","这个问题涉及根据房屋和社区的属性预测房屋价值。 \n","\n","数据集将使用 Pandas 自动下载，但您可以在此处了解更多信息。 \n","\n","- [Boston Housing Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv).\n","- [Boston Housing Dataset Description](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.names).\n","\n","这是一个回归问题，涉及预测单个数值。因此，输出层具有单个节点，并使用默认或线性激活函数（无激活函数）。通过使均方误差 （mse） 损失最小化来拟合模型。 \n","\n","这是回归，而不是分类;因此，我们无法计算分类准确性。有关此内容的更多信息，请参阅教程： \n","- [机器学习中分类和回归的区别](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/)\n","\n","下面列出了在波士顿房价数据集上拟合和评估 MLP 的完整示例。"]},{"cell_type":"code","execution_count":null,"id":"__bohr_old_version_cellId_52__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["339 167\n","MSE: 84.666, RMSE: 9.201\n","Predicted: 23.459\n"]}],"source":["# PyTorch｜建立回归任务的多层感知机模型\n","from numpy import vstack\n","from numpy import sqrt\n","from pandas import read_csv\n","from sklearn.metrics import mean_squared_error\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","from torch import Tensor\n","from torch.nn import Linear\n","from torch.nn import Sigmoid\n","from torch.nn import Module\n","from torch.optim import SGD\n","from torch.nn import MSELoss\n","from torch.nn.init import xavier_uniform_\n"," \n","# 数据集定义\n","class CSVDataset(Dataset):\n","    # 导入数据集\n","    def __init__(self, path):\n","        # 导入传入路径的数据集为 Pandas DataFrame 格式\n","        df = read_csv(path, header=None)\n","        # 设置神经网络的输入与输出\n","        self.X = df.values[:, :-1].astype('float32')\n","        self.y = df.values[:, -1].astype('float32')\n","        # 确保标签有正确的 shape\n","        self.y = self.y.reshape((len(self.y), 1))\n"," \n","    # 定义获得数据集长度的方法\n","    def __len__(self):\n","        return len(self.X)\n"," \n","    # 定义获得某一行数据的方法\n","    def __getitem__(self, idx):\n","        return [self.X[idx], self.y[idx]]\n"," \n","    # 在类内部定义划分训练集和测试集的方法，在本例中，训练集比例为 0.67，测试集比例为 0.33\n","    def get_splits(self, n_test=0.33):\n","        # 确定训练集和测试集的尺寸\n","        test_size = round(n_test * len(self.X))\n","        train_size = len(self.X) - test_size\n","        # 根据尺寸划分训练集和测试集并返回\n","        return random_split(self, [train_size, test_size])\n"," \n","# 模型定义\n","class MLP(Module):\n","    # 定义模型属性\n","    def __init__(self, n_inputs):\n","        super(MLP, self).__init__()\n","        # 输入到隐层 1\n","        self.hidden1 = Linear(n_inputs, 10)\n","        xavier_uniform_(self.hidden1.weight)\n","        self.act1 = Sigmoid()\n","        # 隐层 2\n","        self.hidden2 = Linear(10, 8)\n","        xavier_uniform_(self.hidden2.weight)\n","        self.act2 = Sigmoid()\n","        # 隐层 3 和输出\n","        self.hidden3 = Linear(8, 1)\n","        xavier_uniform_(self.hidden3.weight)\n"," \n","    # 前向传播\n","    def forward(self, X):\n","        # 输入到隐层 1\n","        X = self.hidden1(X)\n","        X = self.act1(X)\n","         # 隐层 2\n","        X = self.hidden2(X)\n","        X = self.act2(X)\n","        # 隐层 3 和输出\n","        X = self.hidden3(X)\n","        return X\n"," \n","# 准备数据集\n","def prepare_data(path):\n","    # 导入数据集\n","    dataset = CSVDataset(path)\n","    # 划分训练集和测试集并返回\n","    train, test = dataset.get_splits()\n","    # 为训练集和测试集创建 DataLoader\n","    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n","    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n","    return train_dl, test_dl\n"," \n","# 训练模型\n","def train_model(train_dl, model):\n","    # 定义优化器\n","    criterion = MSELoss()\n","    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n","    # 枚举 epochs\n","    for epoch in range(100):\n","        # 枚举 mini batches\n","        for i, (inputs, targets) in enumerate(train_dl):\n","            # 梯度清除\n","            optimizer.zero_grad()\n","            # 计算模型输出\n","            yhat = model(inputs)\n","            # 计算损失\n","            loss = criterion(yhat, targets)\n","            # 贡献度分配\n","            loss.backward()\n","            # 升级模型权重\n","            optimizer.step()\n"," \n","# 评估模型\n","def evaluate_model(test_dl, model):\n","    predictions, actuals = list(), list()\n","    for i, (inputs, targets) in enumerate(test_dl):\n","        # 在测试集上评估模型\n","        yhat = model(inputs)\n","        # 转化为 numpy 数据类型\n","        yhat = yhat.detach().numpy()\n","        actual = targets.numpy()\n","        actual = actual.reshape((len(actual), 1))\n","        # 保存\n","        predictions.append(yhat)\n","        actuals.append(actual)\n","    predictions, actuals = vstack(predictions), vstack(actuals)\n","    # 计算均方损失 mse\n","    mse = mean_squared_error(actuals, predictions)\n","    return mse\n"," \n","# 对一行数据进行类预测\n","def predict(row, model):\n","    # 转换源数据\n","    row = Tensor([row])\n","    # 做出预测\n","    yhat = model(row)\n","    # 转化为 numpy 数据类型\n","    yhat = yhat.detach().numpy()\n","    return yhat\n"," \n","# 准备数据\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n","train_dl, test_dl = prepare_data(path)\n","print(len(train_dl.dataset), len(test_dl.dataset))\n","# 定义网络\n","model = MLP(13)\n","# 训练模型\n","train_model(train_dl, model)\n","# 评估模型\n","mse = evaluate_model(test_dl, model)\n","print('MSE: %.3f, RMSE: %.3f' % (mse, sqrt(mse)))\n","# 进行单个预测\n","row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n","yhat = predict(row, model)\n","print('Predicted: %.3f' % yhat)"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_53__","metadata":{},"source":["运行示例后，首先报告训练数据集和测试数据集的长度，然后拟合模型并在测试数据集上对其进行评估。最后，对单行数据进行预测。 \n","\n","注意：根据算法或评估过程的随机性质或数值精度的差异，你的[结果可能会有所不同](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)。请考虑运行几次示例并比较平均结果。 \n","\n","你得到了什么结果？ \n","\n","你能改变模型做得更好吗？\n","\n","你可以试着修改代码以直接输出平均结果吗？\n","\n","<span style='color:orange; font-weight:bold'>不要犹豫，试试直接在 Bohrium Notebook 中实现你的想法。</span>\n","\n","在本例中，我们可以看到该模型实现了大约 103 的 MSE，即大约 10 的 RMSE（单位是千美元）。然后预测单个示例的值为 21（千美元）。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_54__","metadata":{},"source":["#### 3.4 建立图像分类的卷积神经网络模型 <a id='3-4'></a>\n","\n","卷积神经网络（简称 CNN）是一种专为图像输入而设计的网络。 \n","\n","它们由具有[卷积层](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)的模型组成，这些卷积层可以提取特征（称为特征图），而[池化层](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/)会将特征提取到最突出的元素。 \n","\n","CNN最适合图像分类任务，尽管它们也可以用于将图像作为输入的各种任务。\n","\n","一种流行的图像分类任务是 [MNIST handwritten digit classification](https://en.wikipedia.org/wiki/MNIST_database) 手写数字分类。它涉及数以万计的手写数字，必须归类为 0 到 9 之间的数字。 torchvision API提供了一个方便的功能，可以直接下载和加载这个数据集。 下面的示例加载数据集并绘制前几个图像。"]},{"cell_type":"code","execution_count":null,"id":"__bohr_old_version_cellId_55__","metadata":{},"outputs":[{"data":{"remote/url":"https://bohrium.oss-cn-zhangjiakou.aliyuncs.com/article/14076/7ee533d881f34063be8a1043f8eedc14/ab44a944af264b80a5ff478eb4fe296c.png"},"metadata":{},"output_type":"display_data"}],"source":["# 在 PyTorch 中载入 mnist 数据集\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import Compose\n","from torchvision.transforms import ToTensor\n","from matplotlib import pyplot\n","# 定义保存或加载数据集的位置\n","path = '~/.torch/datasets/mnist'\n","# 定义要应用于数据的转换\n","trans = Compose([ToTensor()])\n","# 下载并定义数据集\n","train = MNIST(path, train=True, download=True, transform=trans)\n","test = MNIST(path, train=False, download=True, transform=trans)\n","# 定义如何枚举数据集\n","train_dl = DataLoader(train, batch_size=32, shuffle=True)\n","test_dl = DataLoader(test, batch_size=32, shuffle=True)\n","# 以 batch 方式获取图片\n","i, (inputs, targets) = next(enumerate(train_dl))\n","# 绘图\n","for i in range(25):\n"," # 定义子图\n"," pyplot.subplot(5, 5, i+1)\n"," # 绘制原始像素数据\n"," pyplot.imshow(inputs[i][0], cmap='gray')\n","# 展示图片\n","pyplot.show()"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_56__","metadata":{},"source":["运行示例加载 MNIST 数据集，然后汇总默认训练和测试数据集。\n","\n","上述代码创建了一个网格图，显示训练数据集中手写图像的示例。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_57__","metadata":{},"source":["我们可以训练一个CNN模型来对MNIST数据集中的图像进行分类。 \n","\n","请注意，图像是灰度像素数据的数组，因此，我们必须向数据添加通道维度，然后才能将图像用作模型的输入。 \n","\n","最好将像素值从默认范围 0-255 缩放为零平均值和标准差 1（标准正态分布）。\n","\n","有关缩放像素值的详细信息，请参阅教程： \n","\n","- [How to Manually Scale Image Pixel Data for Deep Learning](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/)\n","\n","下面列出了在MNIST数据集上拟合和评估CNN模型的完整示例。"]},{"cell_type":"code","execution_count":null,"id":"__bohr_old_version_cellId_58__","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["60000 10000\n","Accuracy: 0.987\n"]}],"source":["# PyTorch｜建立图像分类的卷积神经网络模型\n","from numpy import vstack\n","from numpy import argmax\n","from pandas import read_csv\n","from sklearn.metrics import accuracy_score\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import Compose\n","from torchvision.transforms import ToTensor\n","from torchvision.transforms import Normalize\n","from torch.utils.data import DataLoader\n","from torch.nn import Conv2d\n","from torch.nn import MaxPool2d\n","from torch.nn import Linear\n","from torch.nn import ReLU\n","from torch.nn import Softmax\n","from torch.nn import Module\n","from torch.optim import SGD\n","from torch.nn import CrossEntropyLoss\n","from torch.nn.init import kaiming_uniform_\n","from torch.nn.init import xavier_uniform_\n"," \n","# 模型定义\n","class CNN(Module):\n","    # 定义模型属性\n","    def __init__(self, n_channels):\n","        super(CNN, self).__init__()\n","        # 输入到隐层 1\n","        self.hidden1 = Conv2d(n_channels, 32, (3,3))\n","        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n","        self.act1 = ReLU()\n","        # 池化层 1\n","        self.pool1 = MaxPool2d((2,2), stride=(2,2))\n","        # 隐层 2\n","        self.hidden2 = Conv2d(32, 32, (3,3))\n","        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n","        self.act2 = ReLU()\n","        # 池化层 2\n","        self.pool2 = MaxPool2d((2,2), stride=(2,2))\n","        # 全连接层\n","        self.hidden3 = Linear(5*5*32, 100)\n","        kaiming_uniform_(self.hidden3.weight, nonlinearity='relu')\n","        self.act3 = ReLU()\n","        # 输出层\n","        self.hidden4 = Linear(100, 10)\n","        xavier_uniform_(self.hidden4.weight)\n","        self.act4 = Softmax(dim=1)\n"," \n","    # 前向传播\n","    def forward(self, X):\n","        # 输入到隐层 1\n","        X = self.hidden1(X)\n","        X = self.act1(X)\n","        X = self.pool1(X)\n","        # 隐层 2\n","        X = self.hidden2(X)\n","        X = self.act2(X)\n","        X = self.pool2(X)\n","        # 扁平化\n","        X = X.view(-1, 4*4*50)\n","        # 隐层 3\n","        X = self.hidden3(X)\n","        X = self.act3(X)\n","        # 输出层\n","        X = self.hidden4(X)\n","        X = self.act4(X)\n","        return X\n"," \n","# 准备数据集\n","def prepare_data(path):\n","    # 定义标准化\n","    trans = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n","    # 加载数据集\n","    train = MNIST(path, train=True, download=True, transform=trans)\n","    test = MNIST(path, train=False, download=True, transform=trans)\n","    # 为训练集和测试集创建 DataLoader\n","    train_dl = DataLoader(train, batch_size=64, shuffle=True)\n","    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n","    return train_dl, test_dl\n"," \n","# 训练模型\n","def train_model(train_dl, model):\n","    # 定义优化器\n","    criterion = CrossEntropyLoss()\n","    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n","    # 枚举 epochs\n","    for epoch in range(10):\n","        # 枚举 mini batches\n","        for i, (inputs, targets) in enumerate(train_dl):\n","            # 梯度清除\n","            optimizer.zero_grad()\n","            # 计算模型输出\n","            yhat = model(inputs)\n","            # 计算损失\n","            loss = criterion(yhat, targets)\n","            # 贡献度分配\n","            loss.backward()\n","            # 升级模型权重\n","            optimizer.step()\n"," \n","# 评估模型\n","def evaluate_model(test_dl, model):\n","    predictions, actuals = list(), list()\n","    for i, (inputs, targets) in enumerate(test_dl):\n","        # 在测试集上评估模型\n","        yhat = model(inputs)\n","        # 转化为 numpy 数据类型\n","        yhat = yhat.detach().numpy()\n","        actual = targets.numpy()\n","        # 转化为类标签\n","        yhat = argmax(yhat, axis=1)\n","        # 为 stack 格式化数据集\n","        actual = actual.reshape((len(actual), 1))\n","        yhat = yhat.reshape((len(yhat), 1))\n","        # 保存\n","        predictions.append(yhat)\n","        actuals.append(actual)\n","    predictions, actuals = vstack(predictions), vstack(actuals)\n","    # 计算准确度\n","    acc = accuracy_score(actuals, predictions)\n","    return acc\n"," \n","# 准备数据\n","path = '~/.torch/datasets/mnist'\n","train_dl, test_dl = prepare_data(path)\n","print(len(train_dl.dataset), len(test_dl.dataset))\n","# 定义网络\n","model = CNN(1)\n","# # 训练模型\n","train_model(train_dl, model)  # 该步骤运行约需 5 分钟。\n","# 评估模型\n","acc = evaluate_model(test_dl, model)\n","print('Accuracy: %.3f' % acc)"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_59__","metadata":{},"source":["运行示例后，首先报告训练数据集和测试数据集的长度，然后拟合模型并在测试数据集上对其进行评估。最后，对单行数据进行预测。 \n","\n","注意：根据算法或评估过程的随机性质或数值精度的差异，你的[结果可能会有所不同](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)。请考虑运行几次示例并比较平均结果。 \n","\n","你得到了什么结果？ \n","\n","你能改变模型做得更好吗？\n","\n","你可以试着修改代码以直接输出平均结果吗？\n","\n","<span style='color:orange; font-weight:bold'>不要犹豫，试试直接在 Bohrium Notebook 中实现你的想法。</span>\n","\n","在本例中，我们可以看到该模型在测试数据集上实现了大约 98% 的分类准确率。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_60__","metadata":{},"source":["## 总结 <a id='summary'></a>\n","\n","在本教程中，您学习了在 PyTorch 中开发深度学习模型的范式。 \n","\n","具体而言，您了解到： \n","- Torch 和 PyTorch 之间的区别以及如何安装和确认 PyTorch 是否正常工作。 \n","- PyTorch 模型的建立范式以及如何定义、拟合和评估模型。 \n","- 如何为回归、分类和预测建模任务开发 PyTorch 深度学习模型。 \n"," \n","你有什么问题吗？ 欢迎与我们联系 [bohrium@dp.tech](mailto:bohrium@dp.tech) 。"]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_61__","metadata":{},"source":["## 进一步阅读 <a id='furtherreading'></a>\n","\n","如果您希望更深入学习 PyTorch，本节提供有关该主题的更多资源。\n","\n","**书籍**\n","\n","- [Deep Learning](https://amzn.to/2Y8JuBv), 2016.\n","- [Programming PyTorch for Deep Learning: Creating and Deploying Deep Learning Applications](https://amzn.to/2LA71Gq), 2018.\n","- [Deep Learning with PyTorch](https://amzn.to/2Yw2s5q), 2020.\n","- [Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD](https://amzn.to/2P0MQDM), 2020.\n","\n","**PyTorch 项目**\n","\n","- [PyTorch Homepage](https://pytorch.org/).\n","- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n","- [PyTorch Installation Guide](https://pytorch.org/get-started/locally/)\n","- [PyTorch, Wikipedia](https://en.wikipedia.org/wiki/PyTorch).\n","- [PyTorch on GitHub](https://github.com/pytorch/pytorch)."]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_62__","metadata":{},"source":["## 参考 <a id='references'></a>\n","\n","1. [PyTorch Tutorial: How to Develop Deep Learning Models with Python - MachineLearningMastery.com](https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/)\n","2. Zhang, A.; Lipton, Z. C.; Li, M.; Smola, A. J. Dive into Deep Learning. *arXiv preprint arXiv:2106.11342* **2021**."]},{"cell_type":"markdown","id":"__bohr_old_version_cellId_63__","metadata":{},"source":["<a href=\"https://bohrium.dp.tech/notebook/b014bcccd07c488b9349cda979504fd7\" target=\"_blank\"><img src=\"https://cdn.dp.tech/bohrium/web/static/images/open-in-bohrium.svg\" alt=\"Open In Bohrium\"/></a>"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"orig_nbformat_minor":4},"nbformat":4,"nbformat_minor":5}
